{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import StratifiedGroupKFold,StratifiedShuffleSplit,KFold,train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "train=pd.read_csv(\"../dataset/train_features.csv\")\n",
    "y=pd.read_csv(\"../dataset/train_labels.csv\")\n",
    "test=pd.read_csv(\"../dataset/test_features.csv\")\n",
    "ss=pd.read_csv(\"../dataset/submission_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid age_03 urban_03 married_03  n_mar_03 edu_gru_03 n_living_child_03  \\\n",
       "0  aace    NaN      NaN        NaN       NaN        NaN               NaN   \n",
       "1  aanz    NaN      NaN        NaN       NaN        NaN               NaN   \n",
       "\n",
       "   migration_03 glob_hlth_03  adl_dress_03  ...           rrelgimp_12  \\\n",
       "0           NaN          NaN           NaN  ...  2.somewhat important   \n",
       "1           NaN          NaN           NaN  ...      1.very important   \n",
       "\n",
       "   rrfcntx_m_12        rsocact_m_12  rrelgwk_12  a16a_12  a21_12  a22_12  \\\n",
       "0       9.Never             9.Never        0.No      NaN     NaN     NaN   \n",
       "1       9.Never  1.Almost every day        0.No      NaN     NaN     NaN   \n",
       "\n",
       "   a33b_12  a34_12      j11_12  \n",
       "0      NaN     NaN  Concrete 2  \n",
       "1      NaN     NaN  Concrete 2  \n",
       "\n",
       "[2 rows x 184 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abxu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aeol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid age_03 urban_03 married_03  n_mar_03 edu_gru_03 n_living_child_03  \\\n",
       "0  abxu    NaN      NaN        NaN       NaN        NaN               NaN   \n",
       "1  aeol    NaN      NaN        NaN       NaN        NaN               NaN   \n",
       "\n",
       "   migration_03 glob_hlth_03  adl_dress_03  ...       rrelgimp_12  \\\n",
       "0           NaN          NaN           NaN  ...               NaN   \n",
       "1           NaN          NaN           NaN  ...  1.very important   \n",
       "\n",
       "   rrfcntx_m_12  rsocact_m_12  rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  \\\n",
       "0           NaN           NaN         NaN      NaN     NaN     NaN      NaN   \n",
       "1       9.Never       9.Never       1.Yes      NaN     NaN     NaN      NaN   \n",
       "\n",
       "   a34_12                             j11_12  \n",
       "0     NaN  Wood, mosaic, or other covering 1  \n",
       "1     NaN                         Concrete 2  \n",
       "\n",
       "[2 rows x 184 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Columns: 184 entries, uid to j11_12\n",
      "dtypes: float64(140), object(44)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let merge train and label\n",
    "merged_df = pd.merge(train, y, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021\n",
       "1       2021\n",
       "2       2016\n",
       "3       2021\n",
       "4       2021\n",
       "        ... \n",
       "4338    2021\n",
       "4339    2016\n",
       "4340    2021\n",
       "4341    2021\n",
       "4342    2021\n",
       "Name: year, Length: 4343, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid                   0\n",
       "age_03             1456\n",
       "urban_03           1454\n",
       "married_03         1454\n",
       "n_mar_03           1482\n",
       "                   ... \n",
       "a33b_12            4288\n",
       "a34_12             1601\n",
       "j11_12               89\n",
       "year                  0\n",
       "composite_score       0\n",
       "Length: 186, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so many missing values\n",
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets merged test AND sample submission\n",
    "merged_test = pd.merge(test, ss, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2016\n",
       "1       2016\n",
       "2       2021\n",
       "3       2016\n",
       "4       2021\n",
       "        ... \n",
       "1100    2016\n",
       "1101    2021\n",
       "1102    2016\n",
       "1103    2021\n",
       "1104    2021\n",
       "Name: year, Length: 1105, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Target Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df['composite_score'].plot(kind='hist',title='Target Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=merged_df['composite_score']\n",
    "data=pd.concat((merged_df,merged_test)).reset_index(drop=True).copy()\n",
    "data=data.drop(columns=['uid','composite_score'],axis=1)\n",
    "\n",
    "# Get the columns with object datatype\n",
    "object_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert the object columns to category dtype\n",
    "for col in object_cols:\n",
    "    #data[col] = data[col].astype('category').fillna(\"Missing\")\n",
    "    data[col] = pd.Categorical(data[col].fillna(\"Missing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate train and test\n",
    "merged_df=data[:len(merged_df)]\n",
    "merged_test=data[len(merged_df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4343, 184)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1565\n",
      "[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 157.136730\n",
      "0:\tlearn: 61.0968399\ttest: 58.8058395\tbest: 58.8058395 (0)\ttotal: 87.3ms\tremaining: 14m 33s\n",
      "100:\tlearn: 45.4410279\ttest: 45.6028066\tbest: 45.6028066 (100)\ttotal: 2.34s\tremaining: 3m 49s\n",
      "200:\tlearn: 39.0878675\ttest: 41.5456612\tbest: 41.5456612 (200)\ttotal: 4.96s\tremaining: 4m 1s\n",
      "300:\tlearn: 35.5986901\ttest: 39.9273411\tbest: 39.9273411 (300)\ttotal: 7.92s\tremaining: 4m 15s\n",
      "400:\tlearn: 33.2094891\ttest: 39.1314163\tbest: 39.1314163 (400)\ttotal: 10.7s\tremaining: 4m 16s\n",
      "500:\tlearn: 31.4176779\ttest: 38.6480547\tbest: 38.6480547 (500)\ttotal: 13.3s\tremaining: 4m 11s\n",
      "600:\tlearn: 30.1218652\ttest: 38.3368350\tbest: 38.3368350 (600)\ttotal: 15.8s\tremaining: 4m 7s\n",
      "700:\tlearn: 29.0396136\ttest: 38.1174048\tbest: 38.1174048 (700)\ttotal: 18.3s\tremaining: 4m 2s\n",
      "800:\tlearn: 28.1765249\ttest: 37.9571419\tbest: 37.9571419 (800)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "900:\tlearn: 27.3631189\ttest: 37.8359519\tbest: 37.8359519 (900)\ttotal: 23.2s\tremaining: 3m 53s\n",
      "1000:\tlearn: 26.6854148\ttest: 37.7060396\tbest: 37.7059171 (999)\ttotal: 26.1s\tremaining: 3m 54s\n",
      "1100:\tlearn: 25.9836598\ttest: 37.5950522\tbest: 37.5950522 (1100)\ttotal: 29.4s\tremaining: 3m 57s\n",
      "1200:\tlearn: 25.2755455\ttest: 37.4891538\tbest: 37.4891538 (1200)\ttotal: 32.1s\tremaining: 3m 55s\n",
      "1300:\tlearn: 24.6105168\ttest: 37.3926022\tbest: 37.3924316 (1298)\ttotal: 35s\tremaining: 3m 54s\n",
      "1400:\tlearn: 23.9258090\ttest: 37.3240111\tbest: 37.3239032 (1399)\ttotal: 38.3s\tremaining: 3m 55s\n",
      "1500:\tlearn: 23.1768420\ttest: 37.2432973\tbest: 37.2432973 (1500)\ttotal: 41.3s\tremaining: 3m 53s\n",
      "1600:\tlearn: 22.4494470\ttest: 37.1927855\tbest: 37.1910263 (1591)\ttotal: 44.2s\tremaining: 3m 51s\n",
      "1700:\tlearn: 21.7832670\ttest: 37.1244423\tbest: 37.1240429 (1696)\ttotal: 47.3s\tremaining: 3m 50s\n",
      "1800:\tlearn: 21.2058446\ttest: 37.0873275\tbest: 37.0873275 (1800)\ttotal: 50.1s\tremaining: 3m 48s\n",
      "1900:\tlearn: 20.6398615\ttest: 37.0298037\tbest: 37.0298037 (1900)\ttotal: 53.1s\tremaining: 3m 46s\n",
      "2000:\tlearn: 20.0176130\ttest: 36.9825443\tbest: 36.9825443 (2000)\ttotal: 56.3s\tremaining: 3m 45s\n",
      "2100:\tlearn: 19.4370441\ttest: 36.9295941\tbest: 36.9295941 (2100)\ttotal: 59.6s\tremaining: 3m 44s\n",
      "2200:\tlearn: 18.8953118\ttest: 36.8912659\tbest: 36.8912659 (2200)\ttotal: 1m 2s\tremaining: 3m 41s\n",
      "2300:\tlearn: 18.3999280\ttest: 36.8524221\tbest: 36.8524097 (2299)\ttotal: 1m 5s\tremaining: 3m 39s\n",
      "2400:\tlearn: 17.9799441\ttest: 36.8176085\tbest: 36.8173416 (2399)\ttotal: 1m 8s\tremaining: 3m 37s\n",
      "2500:\tlearn: 17.5083622\ttest: 36.7888098\tbest: 36.7863951 (2494)\ttotal: 1m 11s\tremaining: 3m 34s\n",
      "2600:\tlearn: 17.0996144\ttest: 36.7612197\tbest: 36.7608820 (2599)\ttotal: 1m 14s\tremaining: 3m 32s\n",
      "2700:\tlearn: 16.6814348\ttest: 36.7391370\tbest: 36.7391370 (2700)\ttotal: 1m 17s\tremaining: 3m 29s\n",
      "2800:\tlearn: 16.2917057\ttest: 36.7084424\tbest: 36.7076249 (2795)\ttotal: 1m 20s\tremaining: 3m 27s\n",
      "2900:\tlearn: 15.9314976\ttest: 36.6941992\tbest: 36.6933951 (2899)\ttotal: 1m 23s\tremaining: 3m 24s\n",
      "3000:\tlearn: 15.5698204\ttest: 36.6867289\tbest: 36.6866828 (2968)\ttotal: 1m 26s\tremaining: 3m 21s\n",
      "3100:\tlearn: 15.1945936\ttest: 36.6655089\tbest: 36.6653550 (3099)\ttotal: 1m 29s\tremaining: 3m 19s\n",
      "3200:\tlearn: 14.8691131\ttest: 36.6411608\tbest: 36.6409042 (3199)\ttotal: 1m 32s\tremaining: 3m 16s\n",
      "3300:\tlearn: 14.5703165\ttest: 36.6247168\tbest: 36.6235915 (3296)\ttotal: 1m 35s\tremaining: 3m 13s\n",
      "3400:\tlearn: 14.2799347\ttest: 36.6045406\tbest: 36.6045406 (3400)\ttotal: 1m 38s\tremaining: 3m 11s\n",
      "3500:\tlearn: 14.0235511\ttest: 36.5888776\tbest: 36.5885848 (3499)\ttotal: 1m 41s\tremaining: 3m 8s\n",
      "3600:\tlearn: 13.7498341\ttest: 36.5898048\tbest: 36.5858308 (3543)\ttotal: 1m 44s\tremaining: 3m 5s\n",
      "3700:\tlearn: 13.5143747\ttest: 36.5794085\tbest: 36.5790383 (3697)\ttotal: 1m 47s\tremaining: 3m 3s\n",
      "3800:\tlearn: 13.2829866\ttest: 36.5735306\tbest: 36.5708231 (3776)\ttotal: 1m 50s\tremaining: 3m\n",
      "3900:\tlearn: 13.0679218\ttest: 36.5641869\tbest: 36.5641869 (3900)\ttotal: 1m 53s\tremaining: 2m 57s\n",
      "4000:\tlearn: 12.8320951\ttest: 36.5494418\tbest: 36.5485848 (3983)\ttotal: 1m 56s\tremaining: 2m 55s\n",
      "4100:\tlearn: 12.6152979\ttest: 36.5421505\tbest: 36.5416001 (4091)\ttotal: 1m 59s\tremaining: 2m 52s\n",
      "4200:\tlearn: 12.4105339\ttest: 36.5292587\tbest: 36.5292587 (4200)\ttotal: 2m 2s\tremaining: 2m 49s\n",
      "4300:\tlearn: 12.1846440\ttest: 36.5244883\tbest: 36.5238771 (4298)\ttotal: 2m 6s\tremaining: 2m 47s\n",
      "4400:\tlearn: 11.9951569\ttest: 36.5196004\tbest: 36.5173076 (4354)\ttotal: 2m 9s\tremaining: 2m 44s\n",
      "4500:\tlearn: 11.7815892\ttest: 36.5221598\tbest: 36.5169857 (4444)\ttotal: 2m 12s\tremaining: 2m 41s\n",
      "4600:\tlearn: 11.6140948\ttest: 36.5188373\tbest: 36.5169857 (4444)\ttotal: 2m 15s\tremaining: 2m 38s\n",
      "4700:\tlearn: 11.4349415\ttest: 36.5153531\tbest: 36.5153531 (4700)\ttotal: 2m 18s\tremaining: 2m 35s\n",
      "4800:\tlearn: 11.2563215\ttest: 36.5088976\tbest: 36.5088976 (4800)\ttotal: 2m 21s\tremaining: 2m 33s\n",
      "4900:\tlearn: 11.0653295\ttest: 36.4970832\tbest: 36.4967211 (4895)\ttotal: 2m 24s\tremaining: 2m 30s\n",
      "5000:\tlearn: 10.8695620\ttest: 36.4904353\tbest: 36.4903101 (4999)\ttotal: 2m 27s\tremaining: 2m 27s\n",
      "5100:\tlearn: 10.7188535\ttest: 36.4793738\tbest: 36.4786537 (5098)\ttotal: 2m 30s\tremaining: 2m 24s\n",
      "5200:\tlearn: 10.5643047\ttest: 36.4800573\tbest: 36.4786537 (5098)\ttotal: 2m 34s\tremaining: 2m 22s\n",
      "5300:\tlearn: 10.4024245\ttest: 36.4751029\tbest: 36.4737995 (5277)\ttotal: 2m 37s\tremaining: 2m 19s\n",
      "5400:\tlearn: 10.2537598\ttest: 36.4704155\tbest: 36.4689785 (5359)\ttotal: 2m 40s\tremaining: 2m 16s\n",
      "5500:\tlearn: 10.0892639\ttest: 36.4667787\tbest: 36.4654975 (5478)\ttotal: 2m 43s\tremaining: 2m 14s\n",
      "5600:\tlearn: 9.9391060\ttest: 36.4604487\tbest: 36.4594691 (5592)\ttotal: 2m 47s\tremaining: 2m 11s\n",
      "5700:\tlearn: 9.7638891\ttest: 36.4567215\tbest: 36.4567215 (5700)\ttotal: 2m 50s\tremaining: 2m 8s\n",
      "5800:\tlearn: 9.6296542\ttest: 36.4553932\tbest: 36.4553932 (5800)\ttotal: 2m 53s\tremaining: 2m 5s\n",
      "5900:\tlearn: 9.4853367\ttest: 36.4477291\tbest: 36.4477291 (5900)\ttotal: 2m 56s\tremaining: 2m 2s\n",
      "6000:\tlearn: 9.3542688\ttest: 36.4411590\tbest: 36.4411590 (6000)\ttotal: 2m 59s\tremaining: 1m 59s\n",
      "6100:\tlearn: 9.2140346\ttest: 36.4413088\tbest: 36.4387112 (6038)\ttotal: 3m 2s\tremaining: 1m 56s\n",
      "6200:\tlearn: 9.0822900\ttest: 36.4418505\tbest: 36.4387112 (6038)\ttotal: 3m 5s\tremaining: 1m 53s\n",
      "6300:\tlearn: 8.9475066\ttest: 36.4388100\tbest: 36.4387112 (6038)\ttotal: 3m 8s\tremaining: 1m 50s\n",
      "6400:\tlearn: 8.8092712\ttest: 36.4445999\tbest: 36.4385390 (6305)\ttotal: 3m 11s\tremaining: 1m 47s\n",
      "6500:\tlearn: 8.6750206\ttest: 36.4421406\tbest: 36.4385390 (6305)\ttotal: 3m 14s\tremaining: 1m 44s\n",
      "6600:\tlearn: 8.5550143\ttest: 36.4367300\tbest: 36.4367300 (6600)\ttotal: 3m 17s\tremaining: 1m 41s\n",
      "6700:\tlearn: 8.4524290\ttest: 36.4344232\tbest: 36.4343184 (6688)\ttotal: 3m 21s\tremaining: 1m 38s\n",
      "6800:\tlearn: 8.3637324\ttest: 36.4349691\tbest: 36.4340056 (6753)\ttotal: 3m 24s\tremaining: 1m 35s\n",
      "6900:\tlearn: 8.2472591\ttest: 36.4297468\tbest: 36.4284168 (6859)\ttotal: 3m 27s\tremaining: 1m 33s\n",
      "7000:\tlearn: 8.1407266\ttest: 36.4275655\tbest: 36.4270412 (6988)\ttotal: 3m 30s\tremaining: 1m 30s\n",
      "7100:\tlearn: 8.0303315\ttest: 36.4251227\tbest: 36.4248142 (7097)\ttotal: 3m 33s\tremaining: 1m 27s\n",
      "7200:\tlearn: 7.9171127\ttest: 36.4233965\tbest: 36.4210436 (7143)\ttotal: 3m 36s\tremaining: 1m 24s\n",
      "7300:\tlearn: 7.8058411\ttest: 36.4187669\tbest: 36.4187669 (7300)\ttotal: 3m 39s\tremaining: 1m 21s\n",
      "7400:\tlearn: 7.6804825\ttest: 36.4123071\tbest: 36.4119659 (7395)\ttotal: 3m 42s\tremaining: 1m 18s\n",
      "7500:\tlearn: 7.5694407\ttest: 36.4141152\tbest: 36.4119659 (7395)\ttotal: 3m 45s\tremaining: 1m 15s\n",
      "7600:\tlearn: 7.4509310\ttest: 36.4117020\tbest: 36.4109704 (7574)\ttotal: 3m 48s\tremaining: 1m 12s\n",
      "7700:\tlearn: 7.3461658\ttest: 36.4075210\tbest: 36.4058096 (7684)\ttotal: 3m 51s\tremaining: 1m 9s\n",
      "7800:\tlearn: 7.2199802\ttest: 36.4095842\tbest: 36.4058096 (7684)\ttotal: 3m 54s\tremaining: 1m 6s\n",
      "7900:\tlearn: 7.1069357\ttest: 36.4068844\tbest: 36.4054124 (7884)\ttotal: 3m 57s\tremaining: 1m 3s\n",
      "8000:\tlearn: 6.9823419\ttest: 36.4056810\tbest: 36.4019511 (7968)\ttotal: 4m\tremaining: 1m\n",
      "8100:\tlearn: 6.8887243\ttest: 36.4034192\tbest: 36.4019511 (7968)\ttotal: 4m 3s\tremaining: 57.2s\n",
      "8200:\tlearn: 6.7803534\ttest: 36.4027831\tbest: 36.4016074 (8122)\ttotal: 4m 6s\tremaining: 54.2s\n",
      "8300:\tlearn: 6.6760177\ttest: 36.4045502\tbest: 36.4016074 (8122)\ttotal: 4m 9s\tremaining: 51.2s\n",
      "8400:\tlearn: 6.5772731\ttest: 36.4073496\tbest: 36.4016074 (8122)\ttotal: 4m 12s\tremaining: 48.1s\n",
      "8500:\tlearn: 6.4686491\ttest: 36.4040017\tbest: 36.4016074 (8122)\ttotal: 4m 16s\tremaining: 45.1s\n",
      "8600:\tlearn: 6.3742026\ttest: 36.4027607\tbest: 36.4016074 (8122)\ttotal: 4m 19s\tremaining: 42.1s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 36.40160744\n",
      "bestIteration = 8122\n",
      "\n",
      "Shrink model to first 8123 iterations.\n",
      "[0]\tvalidation_0-rmse:58.77700\tvalidation_0-root_mean_squared_error:58.77700\n",
      "[100]\tvalidation_0-rmse:45.87150\tvalidation_0-root_mean_squared_error:45.87149\n",
      "[200]\tvalidation_0-rmse:42.37062\tvalidation_0-root_mean_squared_error:42.37062\n",
      "[300]\tvalidation_0-rmse:40.80716\tvalidation_0-root_mean_squared_error:40.80716\n",
      "[400]\tvalidation_0-rmse:40.00850\tvalidation_0-root_mean_squared_error:40.00850\n",
      "[500]\tvalidation_0-rmse:39.63225\tvalidation_0-root_mean_squared_error:39.63225\n",
      "[600]\tvalidation_0-rmse:39.40642\tvalidation_0-root_mean_squared_error:39.40642\n",
      "[700]\tvalidation_0-rmse:39.24872\tvalidation_0-root_mean_squared_error:39.24872\n",
      "[800]\tvalidation_0-rmse:39.13328\tvalidation_0-root_mean_squared_error:39.13328\n",
      "[900]\tvalidation_0-rmse:39.04278\tvalidation_0-root_mean_squared_error:39.04278\n",
      "[1000]\tvalidation_0-rmse:38.97120\tvalidation_0-root_mean_squared_error:38.97120\n",
      "[1100]\tvalidation_0-rmse:38.87067\tvalidation_0-root_mean_squared_error:38.87067\n",
      "[1200]\tvalidation_0-rmse:38.80425\tvalidation_0-root_mean_squared_error:38.80425\n",
      "[1300]\tvalidation_0-rmse:38.75112\tvalidation_0-root_mean_squared_error:38.75112\n",
      "[1400]\tvalidation_0-rmse:38.71132\tvalidation_0-root_mean_squared_error:38.71131\n",
      "[1500]\tvalidation_0-rmse:38.64264\tvalidation_0-root_mean_squared_error:38.64263\n",
      "[1600]\tvalidation_0-rmse:38.58799\tvalidation_0-root_mean_squared_error:38.58799\n",
      "[1700]\tvalidation_0-rmse:38.55403\tvalidation_0-root_mean_squared_error:38.55403\n",
      "[1800]\tvalidation_0-rmse:38.51003\tvalidation_0-root_mean_squared_error:38.51003\n",
      "[1900]\tvalidation_0-rmse:38.46614\tvalidation_0-root_mean_squared_error:38.46614\n",
      "[2000]\tvalidation_0-rmse:38.41804\tvalidation_0-root_mean_squared_error:38.41804\n",
      "[2100]\tvalidation_0-rmse:38.37496\tvalidation_0-root_mean_squared_error:38.37496\n",
      "[2200]\tvalidation_0-rmse:38.33310\tvalidation_0-root_mean_squared_error:38.33310\n",
      "[2300]\tvalidation_0-rmse:38.28201\tvalidation_0-root_mean_squared_error:38.28201\n",
      "[2400]\tvalidation_0-rmse:38.26208\tvalidation_0-root_mean_squared_error:38.26208\n",
      "[2500]\tvalidation_0-rmse:38.22938\tvalidation_0-root_mean_squared_error:38.22938\n",
      "[2600]\tvalidation_0-rmse:38.20272\tvalidation_0-root_mean_squared_error:38.20272\n",
      "[2700]\tvalidation_0-rmse:38.19138\tvalidation_0-root_mean_squared_error:38.19138\n",
      "[2800]\tvalidation_0-rmse:38.17518\tvalidation_0-root_mean_squared_error:38.17519\n",
      "[2900]\tvalidation_0-rmse:38.16945\tvalidation_0-root_mean_squared_error:38.16945\n",
      "[3000]\tvalidation_0-rmse:38.15760\tvalidation_0-root_mean_squared_error:38.15760\n",
      "[3100]\tvalidation_0-rmse:38.16990\tvalidation_0-root_mean_squared_error:38.16989\n",
      "[3200]\tvalidation_0-rmse:38.18416\tvalidation_0-root_mean_squared_error:38.18416\n",
      "[3300]\tvalidation_0-rmse:38.18645\tvalidation_0-root_mean_squared_error:38.18645\n",
      "[3400]\tvalidation_0-rmse:38.19213\tvalidation_0-root_mean_squared_error:38.19214\n",
      "[3495]\tvalidation_0-rmse:38.19632\tvalidation_0-root_mean_squared_error:38.19632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:32, 272.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 157.271445\n",
      "0:\tlearn: 59.9979103\ttest: 63.2095608\tbest: 63.2095608 (0)\ttotal: 108ms\tremaining: 18m 1s\n",
      "100:\tlearn: 45.1486532\ttest: 47.5175717\tbest: 47.5175717 (100)\ttotal: 2.58s\tremaining: 4m 12s\n",
      "200:\tlearn: 39.0906320\ttest: 42.2019668\tbest: 42.2019668 (200)\ttotal: 5.42s\tremaining: 4m 24s\n",
      "300:\tlearn: 35.7810579\ttest: 40.0875359\tbest: 40.0875359 (300)\ttotal: 8.28s\tremaining: 4m 26s\n",
      "400:\tlearn: 33.4582687\ttest: 39.0410680\tbest: 39.0410680 (400)\ttotal: 11.1s\tremaining: 4m 24s\n",
      "500:\tlearn: 31.8339698\ttest: 38.4222289\tbest: 38.4222289 (500)\ttotal: 13.9s\tremaining: 4m 24s\n",
      "600:\tlearn: 30.4534694\ttest: 38.0403618\tbest: 38.0403618 (600)\ttotal: 16.7s\tremaining: 4m 21s\n",
      "700:\tlearn: 29.4400671\ttest: 37.8087585\tbest: 37.8087585 (700)\ttotal: 19.5s\tremaining: 4m 18s\n",
      "800:\tlearn: 28.4904281\ttest: 37.6239716\tbest: 37.6239716 (800)\ttotal: 22.1s\tremaining: 4m 13s\n",
      "900:\tlearn: 27.5077689\ttest: 37.4530028\tbest: 37.4530028 (900)\ttotal: 25s\tremaining: 4m 12s\n",
      "1000:\tlearn: 26.5939412\ttest: 37.3155630\tbest: 37.3155630 (1000)\ttotal: 28s\tremaining: 4m 11s\n",
      "1100:\tlearn: 25.8106802\ttest: 37.1859183\tbest: 37.1847637 (1098)\ttotal: 31.1s\tremaining: 4m 11s\n",
      "1200:\tlearn: 25.0415003\ttest: 37.0820230\tbest: 37.0820230 (1200)\ttotal: 34.1s\tremaining: 4m 10s\n",
      "1300:\tlearn: 24.2060608\ttest: 36.9783396\tbest: 36.9783396 (1300)\ttotal: 37.3s\tremaining: 4m 9s\n",
      "1400:\tlearn: 23.4547949\ttest: 36.8871159\tbest: 36.8871159 (1400)\ttotal: 40.3s\tremaining: 4m 7s\n",
      "1500:\tlearn: 22.8335505\ttest: 36.8061968\tbest: 36.8061968 (1500)\ttotal: 43.3s\tremaining: 4m 5s\n",
      "1600:\tlearn: 22.1702881\ttest: 36.7387082\tbest: 36.7387082 (1600)\ttotal: 46.3s\tremaining: 4m 3s\n",
      "1700:\tlearn: 21.5394578\ttest: 36.6807695\tbest: 36.6799396 (1699)\ttotal: 49.3s\tremaining: 4m\n",
      "1800:\tlearn: 20.8794814\ttest: 36.6257672\tbest: 36.6241547 (1799)\ttotal: 52.3s\tremaining: 3m 58s\n",
      "1900:\tlearn: 20.3232951\ttest: 36.5688325\tbest: 36.5674900 (1897)\ttotal: 55.4s\tremaining: 3m 56s\n",
      "2000:\tlearn: 19.7700467\ttest: 36.5294288\tbest: 36.5287194 (1998)\ttotal: 58.4s\tremaining: 3m 53s\n",
      "2100:\tlearn: 19.2386819\ttest: 36.4915784\tbest: 36.4915784 (2100)\ttotal: 1m 1s\tremaining: 3m 51s\n",
      "2200:\tlearn: 18.6950135\ttest: 36.4454020\tbest: 36.4435800 (2197)\ttotal: 1m 4s\tremaining: 3m 49s\n",
      "2300:\tlearn: 18.2222011\ttest: 36.4038527\tbest: 36.4038527 (2300)\ttotal: 1m 7s\tremaining: 3m 47s\n",
      "2400:\tlearn: 17.7558342\ttest: 36.3790723\tbest: 36.3790723 (2400)\ttotal: 1m 11s\tremaining: 3m 45s\n",
      "2500:\tlearn: 17.3588071\ttest: 36.3546361\tbest: 36.3531604 (2485)\ttotal: 1m 14s\tremaining: 3m 42s\n",
      "2600:\tlearn: 16.9131853\ttest: 36.3308881\tbest: 36.3303358 (2599)\ttotal: 1m 17s\tremaining: 3m 40s\n",
      "2700:\tlearn: 16.5167733\ttest: 36.3140649\tbest: 36.3140649 (2700)\ttotal: 1m 20s\tremaining: 3m 37s\n",
      "2800:\tlearn: 16.0965423\ttest: 36.2980620\tbest: 36.2949674 (2789)\ttotal: 1m 23s\tremaining: 3m 34s\n",
      "2900:\tlearn: 15.7139517\ttest: 36.2739113\tbest: 36.2732278 (2898)\ttotal: 1m 26s\tremaining: 3m 32s\n",
      "3000:\tlearn: 15.3384300\ttest: 36.2494106\tbest: 36.2493901 (2999)\ttotal: 1m 30s\tremaining: 3m 30s\n",
      "3100:\tlearn: 15.0260185\ttest: 36.2298649\tbest: 36.2298649 (3100)\ttotal: 1m 33s\tremaining: 3m 27s\n",
      "3200:\tlearn: 14.7038017\ttest: 36.2122879\tbest: 36.2122879 (3200)\ttotal: 1m 36s\tremaining: 3m 24s\n",
      "3300:\tlearn: 14.3721927\ttest: 36.2033348\tbest: 36.2019346 (3272)\ttotal: 1m 39s\tremaining: 3m 21s\n",
      "3400:\tlearn: 14.0792748\ttest: 36.1838382\tbest: 36.1836044 (3399)\ttotal: 1m 42s\tremaining: 3m 19s\n",
      "3500:\tlearn: 13.7990357\ttest: 36.1780921\tbest: 36.1774945 (3471)\ttotal: 1m 45s\tremaining: 3m 16s\n",
      "3600:\tlearn: 13.5282200\ttest: 36.1621248\tbest: 36.1621248 (3600)\ttotal: 1m 48s\tremaining: 3m 13s\n",
      "3700:\tlearn: 13.2594563\ttest: 36.1514836\tbest: 36.1492632 (3689)\ttotal: 1m 51s\tremaining: 3m 10s\n",
      "3800:\tlearn: 12.9753451\ttest: 36.1432513\tbest: 36.1424212 (3798)\ttotal: 1m 54s\tremaining: 3m 7s\n",
      "3900:\tlearn: 12.6721028\ttest: 36.1385806\tbest: 36.1363182 (3884)\ttotal: 1m 57s\tremaining: 3m 4s\n",
      "4000:\tlearn: 12.4341785\ttest: 36.1336836\tbest: 36.1333138 (3998)\ttotal: 2m\tremaining: 3m 1s\n",
      "4100:\tlearn: 12.1722127\ttest: 36.1222212\tbest: 36.1211739 (4077)\ttotal: 2m 4s\tremaining: 2m 58s\n",
      "4200:\tlearn: 11.9132106\ttest: 36.1087948\tbest: 36.1087948 (4200)\ttotal: 2m 7s\tremaining: 2m 55s\n",
      "4300:\tlearn: 11.6875102\ttest: 36.1004300\tbest: 36.0993088 (4245)\ttotal: 2m 10s\tremaining: 2m 52s\n",
      "4400:\tlearn: 11.4462962\ttest: 36.0935277\tbest: 36.0925060 (4393)\ttotal: 2m 13s\tremaining: 2m 49s\n",
      "4500:\tlearn: 11.2428315\ttest: 36.0936694\tbest: 36.0908807 (4420)\ttotal: 2m 16s\tremaining: 2m 46s\n",
      "4600:\tlearn: 11.0268941\ttest: 36.0963873\tbest: 36.0898709 (4511)\ttotal: 2m 19s\tremaining: 2m 44s\n",
      "4700:\tlearn: 10.7801380\ttest: 36.0918238\tbest: 36.0898709 (4511)\ttotal: 2m 22s\tremaining: 2m 41s\n",
      "4800:\tlearn: 10.5980470\ttest: 36.0843832\tbest: 36.0842584 (4799)\ttotal: 2m 26s\tremaining: 2m 38s\n",
      "4900:\tlearn: 10.3938145\ttest: 36.0766310\tbest: 36.0756729 (4898)\ttotal: 2m 29s\tremaining: 2m 35s\n",
      "5000:\tlearn: 10.2024905\ttest: 36.0686313\tbest: 36.0671188 (4991)\ttotal: 2m 32s\tremaining: 2m 32s\n",
      "5100:\tlearn: 10.0031946\ttest: 36.0672790\tbest: 36.0663767 (5067)\ttotal: 2m 35s\tremaining: 2m 29s\n",
      "5200:\tlearn: 9.8254114\ttest: 36.0644655\tbest: 36.0636098 (5195)\ttotal: 2m 38s\tremaining: 2m 26s\n",
      "5300:\tlearn: 9.6612663\ttest: 36.0593095\tbest: 36.0593095 (5300)\ttotal: 2m 41s\tremaining: 2m 23s\n",
      "5400:\tlearn: 9.4987080\ttest: 36.0596317\tbest: 36.0569621 (5337)\ttotal: 2m 44s\tremaining: 2m 20s\n",
      "5500:\tlearn: 9.3255172\ttest: 36.0624607\tbest: 36.0569621 (5337)\ttotal: 2m 48s\tremaining: 2m 17s\n",
      "5600:\tlearn: 9.1691211\ttest: 36.0636531\tbest: 36.0569621 (5337)\ttotal: 2m 51s\tremaining: 2m 14s\n",
      "5700:\tlearn: 9.0143938\ttest: 36.0662827\tbest: 36.0569621 (5337)\ttotal: 2m 54s\tremaining: 2m 11s\n",
      "5800:\tlearn: 8.8652529\ttest: 36.0684153\tbest: 36.0569621 (5337)\ttotal: 2m 57s\tremaining: 2m 8s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 36.05696207\n",
      "bestIteration = 5337\n",
      "\n",
      "Shrink model to first 5338 iterations.\n",
      "[0]\tvalidation_0-rmse:63.17007\tvalidation_0-root_mean_squared_error:63.17006\n",
      "[100]\tvalidation_0-rmse:47.39228\tvalidation_0-root_mean_squared_error:47.39228\n",
      "[200]\tvalidation_0-rmse:42.62799\tvalidation_0-root_mean_squared_error:42.62799\n",
      "[300]\tvalidation_0-rmse:40.77468\tvalidation_0-root_mean_squared_error:40.77468\n",
      "[400]\tvalidation_0-rmse:39.83632\tvalidation_0-root_mean_squared_error:39.83632\n",
      "[500]\tvalidation_0-rmse:39.31773\tvalidation_0-root_mean_squared_error:39.31773\n",
      "[600]\tvalidation_0-rmse:39.00753\tvalidation_0-root_mean_squared_error:39.00753\n",
      "[700]\tvalidation_0-rmse:38.80582\tvalidation_0-root_mean_squared_error:38.80582\n",
      "[800]\tvalidation_0-rmse:38.63751\tvalidation_0-root_mean_squared_error:38.63751\n",
      "[900]\tvalidation_0-rmse:38.49718\tvalidation_0-root_mean_squared_error:38.49718\n",
      "[1000]\tvalidation_0-rmse:38.39796\tvalidation_0-root_mean_squared_error:38.39796\n",
      "[1100]\tvalidation_0-rmse:38.32680\tvalidation_0-root_mean_squared_error:38.32681\n",
      "[1200]\tvalidation_0-rmse:38.25359\tvalidation_0-root_mean_squared_error:38.25359\n",
      "[1300]\tvalidation_0-rmse:38.18207\tvalidation_0-root_mean_squared_error:38.18208\n",
      "[1400]\tvalidation_0-rmse:38.12642\tvalidation_0-root_mean_squared_error:38.12642\n",
      "[1500]\tvalidation_0-rmse:38.07561\tvalidation_0-root_mean_squared_error:38.07561\n",
      "[1600]\tvalidation_0-rmse:38.03486\tvalidation_0-root_mean_squared_error:38.03486\n",
      "[1700]\tvalidation_0-rmse:37.99129\tvalidation_0-root_mean_squared_error:37.99130\n",
      "[1800]\tvalidation_0-rmse:37.95093\tvalidation_0-root_mean_squared_error:37.95093\n",
      "[1900]\tvalidation_0-rmse:37.92233\tvalidation_0-root_mean_squared_error:37.92233\n",
      "[2000]\tvalidation_0-rmse:37.85929\tvalidation_0-root_mean_squared_error:37.85929\n",
      "[2100]\tvalidation_0-rmse:37.81474\tvalidation_0-root_mean_squared_error:37.81474\n",
      "[2200]\tvalidation_0-rmse:37.79602\tvalidation_0-root_mean_squared_error:37.79602\n",
      "[2300]\tvalidation_0-rmse:37.76290\tvalidation_0-root_mean_squared_error:37.76290\n",
      "[2400]\tvalidation_0-rmse:37.71910\tvalidation_0-root_mean_squared_error:37.71909\n",
      "[2500]\tvalidation_0-rmse:37.67392\tvalidation_0-root_mean_squared_error:37.67392\n",
      "[2600]\tvalidation_0-rmse:37.65547\tvalidation_0-root_mean_squared_error:37.65547\n",
      "[2700]\tvalidation_0-rmse:37.63159\tvalidation_0-root_mean_squared_error:37.63159\n",
      "[2800]\tvalidation_0-rmse:37.62763\tvalidation_0-root_mean_squared_error:37.62763\n",
      "[2900]\tvalidation_0-rmse:37.62054\tvalidation_0-root_mean_squared_error:37.62054\n",
      "[3000]\tvalidation_0-rmse:37.60133\tvalidation_0-root_mean_squared_error:37.60133\n",
      "[3100]\tvalidation_0-rmse:37.58648\tvalidation_0-root_mean_squared_error:37.58648\n",
      "[3200]\tvalidation_0-rmse:37.56693\tvalidation_0-root_mean_squared_error:37.56693\n",
      "[3300]\tvalidation_0-rmse:37.55697\tvalidation_0-root_mean_squared_error:37.55697\n",
      "[3400]\tvalidation_0-rmse:37.53713\tvalidation_0-root_mean_squared_error:37.53713\n",
      "[3500]\tvalidation_0-rmse:37.53162\tvalidation_0-root_mean_squared_error:37.53162\n",
      "[3600]\tvalidation_0-rmse:37.52625\tvalidation_0-root_mean_squared_error:37.52625\n",
      "[3700]\tvalidation_0-rmse:37.52653\tvalidation_0-root_mean_squared_error:37.52653\n",
      "[3800]\tvalidation_0-rmse:37.53527\tvalidation_0-root_mean_squared_error:37.53527\n",
      "[3900]\tvalidation_0-rmse:37.53299\tvalidation_0-root_mean_squared_error:37.53299\n",
      "[4000]\tvalidation_0-rmse:37.53233\tvalidation_0-root_mean_squared_error:37.53233\n",
      "[4100]\tvalidation_0-rmse:37.51143\tvalidation_0-root_mean_squared_error:37.51143\n",
      "[4200]\tvalidation_0-rmse:37.51188\tvalidation_0-root_mean_squared_error:37.51188\n",
      "[4300]\tvalidation_0-rmse:37.50891\tvalidation_0-root_mean_squared_error:37.50891\n",
      "[4400]\tvalidation_0-rmse:37.50781\tvalidation_0-root_mean_squared_error:37.50781\n",
      "[4500]\tvalidation_0-rmse:37.49228\tvalidation_0-root_mean_squared_error:37.49228\n",
      "[4600]\tvalidation_0-rmse:37.47020\tvalidation_0-root_mean_squared_error:37.47020\n",
      "[4700]\tvalidation_0-rmse:37.46580\tvalidation_0-root_mean_squared_error:37.46580\n",
      "[4800]\tvalidation_0-rmse:37.47249\tvalidation_0-root_mean_squared_error:37.47248\n",
      "[4900]\tvalidation_0-rmse:37.48039\tvalidation_0-root_mean_squared_error:37.48039\n",
      "[5000]\tvalidation_0-rmse:37.49710\tvalidation_0-root_mean_squared_error:37.49710\n",
      "[5100]\tvalidation_0-rmse:37.50735\tvalidation_0-root_mean_squared_error:37.50735\n",
      "[5200]\tvalidation_0-rmse:37.50806\tvalidation_0-root_mean_squared_error:37.50806\n",
      "[5228]\tvalidation_0-rmse:37.50314\tvalidation_0-root_mean_squared_error:37.50315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:50, 228.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1574\n",
      "[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 156.375360\n",
      "0:\tlearn: 60.9011270\ttest: 59.6063548\tbest: 59.6063548 (0)\ttotal: 18.9ms\tremaining: 3m 9s\n",
      "100:\tlearn: 45.0866310\ttest: 46.6020960\tbest: 46.6020960 (100)\ttotal: 2.3s\tremaining: 3m 45s\n",
      "200:\tlearn: 38.8123756\ttest: 42.7566805\tbest: 42.7566805 (200)\ttotal: 5.15s\tremaining: 4m 11s\n",
      "300:\tlearn: 35.1670499\ttest: 41.0863368\tbest: 41.0863368 (300)\ttotal: 8.03s\tremaining: 4m 18s\n",
      "400:\tlearn: 32.7953003\ttest: 40.3183533\tbest: 40.3183533 (400)\ttotal: 10.8s\tremaining: 4m 18s\n",
      "500:\tlearn: 31.0434299\ttest: 39.8397078\tbest: 39.8397078 (500)\ttotal: 13.6s\tremaining: 4m 18s\n",
      "600:\tlearn: 29.7852070\ttest: 39.5566473\tbest: 39.5566473 (600)\ttotal: 16.4s\tremaining: 4m 16s\n",
      "700:\tlearn: 28.7523588\ttest: 39.3672862\tbest: 39.3672862 (700)\ttotal: 19.1s\tremaining: 4m 14s\n",
      "800:\tlearn: 27.7153668\ttest: 39.1789621\tbest: 39.1789621 (800)\ttotal: 22s\tremaining: 4m 12s\n",
      "900:\tlearn: 26.8477939\ttest: 39.0294404\tbest: 39.0284130 (898)\ttotal: 25.2s\tremaining: 4m 14s\n",
      "1000:\tlearn: 26.0117468\ttest: 38.9229916\tbest: 38.9229916 (1000)\ttotal: 28.3s\tremaining: 4m 14s\n",
      "1100:\tlearn: 25.1412216\ttest: 38.8023264\tbest: 38.8022895 (1099)\ttotal: 31.1s\tremaining: 4m 11s\n",
      "1200:\tlearn: 24.3124954\ttest: 38.6969107\tbest: 38.6969107 (1200)\ttotal: 34.1s\tremaining: 4m 9s\n",
      "1300:\tlearn: 23.5796471\ttest: 38.6056001\tbest: 38.6056001 (1300)\ttotal: 37s\tremaining: 4m 7s\n",
      "1400:\tlearn: 22.8754128\ttest: 38.5227921\tbest: 38.5227921 (1400)\ttotal: 39.9s\tremaining: 4m 4s\n",
      "1500:\tlearn: 22.2461574\ttest: 38.4730581\tbest: 38.4726585 (1496)\ttotal: 42.8s\tremaining: 4m 2s\n",
      "1600:\tlearn: 21.6341953\ttest: 38.3919327\tbest: 38.3874315 (1592)\ttotal: 45.9s\tremaining: 4m\n",
      "1700:\tlearn: 20.9524254\ttest: 38.3445498\tbest: 38.3393222 (1687)\ttotal: 48.9s\tremaining: 3m 58s\n",
      "1800:\tlearn: 20.4169421\ttest: 38.3086127\tbest: 38.3086127 (1800)\ttotal: 51.8s\tremaining: 3m 55s\n",
      "1900:\tlearn: 19.9165695\ttest: 38.2688423\tbest: 38.2688423 (1900)\ttotal: 54.9s\tremaining: 3m 53s\n",
      "2000:\tlearn: 19.3684638\ttest: 38.2403728\tbest: 38.2403728 (2000)\ttotal: 57.9s\tremaining: 3m 51s\n",
      "2100:\tlearn: 18.8605487\ttest: 38.1832520\tbest: 38.1828060 (2099)\ttotal: 1m\tremaining: 3m 49s\n",
      "2200:\tlearn: 18.3568176\ttest: 38.1500586\tbest: 38.1500586 (2200)\ttotal: 1m 3s\tremaining: 3m 46s\n",
      "2300:\tlearn: 17.9146606\ttest: 38.1178445\tbest: 38.1178445 (2300)\ttotal: 1m 7s\tremaining: 3m 44s\n",
      "2400:\tlearn: 17.4933766\ttest: 38.0875947\tbest: 38.0862034 (2394)\ttotal: 1m 9s\tremaining: 3m 41s\n",
      "2500:\tlearn: 17.0456942\ttest: 38.0689714\tbest: 38.0658154 (2492)\ttotal: 1m 12s\tremaining: 3m 38s\n",
      "2600:\tlearn: 16.6630474\ttest: 38.0478217\tbest: 38.0473473 (2598)\ttotal: 1m 16s\tremaining: 3m 36s\n",
      "2700:\tlearn: 16.2372086\ttest: 38.0150772\tbest: 38.0150772 (2700)\ttotal: 1m 19s\tremaining: 3m 34s\n",
      "2800:\tlearn: 15.8209723\ttest: 37.9833750\tbest: 37.9833750 (2800)\ttotal: 1m 22s\tremaining: 3m 31s\n",
      "2900:\tlearn: 15.4599834\ttest: 37.9597023\tbest: 37.9595530 (2899)\ttotal: 1m 25s\tremaining: 3m 29s\n",
      "3000:\tlearn: 15.1227124\ttest: 37.9407108\tbest: 37.9400501 (2999)\ttotal: 1m 28s\tremaining: 3m 26s\n",
      "3100:\tlearn: 14.7767706\ttest: 37.9247651\tbest: 37.9242502 (3095)\ttotal: 1m 31s\tremaining: 3m 24s\n",
      "3200:\tlearn: 14.4553050\ttest: 37.9018157\tbest: 37.9018157 (3200)\ttotal: 1m 34s\tremaining: 3m 20s\n",
      "3300:\tlearn: 14.0999993\ttest: 37.8762824\tbest: 37.8758722 (3298)\ttotal: 1m 37s\tremaining: 3m 18s\n",
      "3400:\tlearn: 13.8017384\ttest: 37.8602580\tbest: 37.8590199 (3380)\ttotal: 1m 40s\tremaining: 3m 15s\n",
      "3500:\tlearn: 13.5117328\ttest: 37.8472732\tbest: 37.8469034 (3495)\ttotal: 1m 43s\tremaining: 3m 12s\n",
      "3600:\tlearn: 13.2426024\ttest: 37.8335630\tbest: 37.8332420 (3593)\ttotal: 1m 47s\tremaining: 3m 10s\n",
      "3700:\tlearn: 12.9595998\ttest: 37.8223007\tbest: 37.8199686 (3680)\ttotal: 1m 50s\tremaining: 3m 7s\n",
      "3800:\tlearn: 12.7019068\ttest: 37.8181810\tbest: 37.8148286 (3770)\ttotal: 1m 53s\tremaining: 3m 5s\n",
      "3900:\tlearn: 12.4618588\ttest: 37.8068958\tbest: 37.8060119 (3890)\ttotal: 1m 57s\tremaining: 3m 3s\n",
      "4000:\tlearn: 12.2032938\ttest: 37.7962754\tbest: 37.7962754 (4000)\ttotal: 2m\tremaining: 3m\n",
      "4100:\tlearn: 11.9220021\ttest: 37.7828329\tbest: 37.7819692 (4077)\ttotal: 2m 3s\tremaining: 2m 58s\n",
      "4200:\tlearn: 11.6767652\ttest: 37.7711709\tbest: 37.7707408 (4147)\ttotal: 2m 6s\tremaining: 2m 55s\n",
      "4300:\tlearn: 11.4156869\ttest: 37.7567637\tbest: 37.7549568 (4289)\ttotal: 2m 10s\tremaining: 2m 52s\n",
      "4400:\tlearn: 11.1737964\ttest: 37.7411988\tbest: 37.7411988 (4400)\ttotal: 2m 13s\tremaining: 2m 49s\n",
      "4500:\tlearn: 10.9511187\ttest: 37.7403713\tbest: 37.7384113 (4469)\ttotal: 2m 16s\tremaining: 2m 46s\n",
      "4600:\tlearn: 10.7616043\ttest: 37.7394338\tbest: 37.7384113 (4469)\ttotal: 2m 19s\tremaining: 2m 43s\n",
      "4700:\tlearn: 10.5913173\ttest: 37.7362767\tbest: 37.7340532 (4682)\ttotal: 2m 22s\tremaining: 2m 41s\n",
      "4800:\tlearn: 10.3800510\ttest: 37.7312292\tbest: 37.7302589 (4792)\ttotal: 2m 26s\tremaining: 2m 38s\n",
      "4900:\tlearn: 10.1841125\ttest: 37.7235028\tbest: 37.7231500 (4898)\ttotal: 2m 29s\tremaining: 2m 35s\n",
      "5000:\tlearn: 10.0074671\ttest: 37.7153314\tbest: 37.7153314 (5000)\ttotal: 2m 33s\tremaining: 2m 33s\n",
      "5100:\tlearn: 9.8127645\ttest: 37.7048075\tbest: 37.7037462 (5086)\ttotal: 2m 37s\tremaining: 2m 30s\n",
      "5200:\tlearn: 9.6182264\ttest: 37.7121722\tbest: 37.7037462 (5086)\ttotal: 2m 40s\tremaining: 2m 28s\n",
      "5300:\tlearn: 9.4349116\ttest: 37.7172704\tbest: 37.7037462 (5086)\ttotal: 2m 43s\tremaining: 2m 25s\n",
      "5400:\tlearn: 9.2539739\ttest: 37.7145230\tbest: 37.7037462 (5086)\ttotal: 2m 47s\tremaining: 2m 22s\n",
      "5500:\tlearn: 9.0921935\ttest: 37.7107864\tbest: 37.7037462 (5086)\ttotal: 2m 50s\tremaining: 2m 19s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 37.70374621\n",
      "bestIteration = 5086\n",
      "\n",
      "Shrink model to first 5087 iterations.\n",
      "[0]\tvalidation_0-rmse:59.59052\tvalidation_0-root_mean_squared_error:59.59052\n",
      "[100]\tvalidation_0-rmse:46.84483\tvalidation_0-root_mean_squared_error:46.84483\n",
      "[200]\tvalidation_0-rmse:43.32111\tvalidation_0-root_mean_squared_error:43.32111\n",
      "[300]\tvalidation_0-rmse:41.85541\tvalidation_0-root_mean_squared_error:41.85541\n",
      "[400]\tvalidation_0-rmse:41.14360\tvalidation_0-root_mean_squared_error:41.14360\n",
      "[500]\tvalidation_0-rmse:40.73692\tvalidation_0-root_mean_squared_error:40.73692\n",
      "[600]\tvalidation_0-rmse:40.48219\tvalidation_0-root_mean_squared_error:40.48219\n",
      "[700]\tvalidation_0-rmse:40.33168\tvalidation_0-root_mean_squared_error:40.33168\n",
      "[800]\tvalidation_0-rmse:40.19536\tvalidation_0-root_mean_squared_error:40.19536\n",
      "[900]\tvalidation_0-rmse:40.10266\tvalidation_0-root_mean_squared_error:40.10265\n",
      "[1000]\tvalidation_0-rmse:40.03159\tvalidation_0-root_mean_squared_error:40.03159\n",
      "[1100]\tvalidation_0-rmse:39.97316\tvalidation_0-root_mean_squared_error:39.97316\n",
      "[1200]\tvalidation_0-rmse:39.91156\tvalidation_0-root_mean_squared_error:39.91156\n",
      "[1300]\tvalidation_0-rmse:39.86706\tvalidation_0-root_mean_squared_error:39.86706\n",
      "[1400]\tvalidation_0-rmse:39.82785\tvalidation_0-root_mean_squared_error:39.82785\n",
      "[1500]\tvalidation_0-rmse:39.78978\tvalidation_0-root_mean_squared_error:39.78978\n",
      "[1600]\tvalidation_0-rmse:39.74252\tvalidation_0-root_mean_squared_error:39.74252\n",
      "[1700]\tvalidation_0-rmse:39.71850\tvalidation_0-root_mean_squared_error:39.71850\n",
      "[1800]\tvalidation_0-rmse:39.68936\tvalidation_0-root_mean_squared_error:39.68936\n",
      "[1900]\tvalidation_0-rmse:39.65974\tvalidation_0-root_mean_squared_error:39.65974\n",
      "[2000]\tvalidation_0-rmse:39.62421\tvalidation_0-root_mean_squared_error:39.62421\n",
      "[2100]\tvalidation_0-rmse:39.60185\tvalidation_0-root_mean_squared_error:39.60185\n",
      "[2200]\tvalidation_0-rmse:39.57988\tvalidation_0-root_mean_squared_error:39.57988\n",
      "[2300]\tvalidation_0-rmse:39.56201\tvalidation_0-root_mean_squared_error:39.56201\n",
      "[2400]\tvalidation_0-rmse:39.56097\tvalidation_0-root_mean_squared_error:39.56097\n",
      "[2500]\tvalidation_0-rmse:39.55311\tvalidation_0-root_mean_squared_error:39.55312\n",
      "[2600]\tvalidation_0-rmse:39.54382\tvalidation_0-root_mean_squared_error:39.54382\n",
      "[2700]\tvalidation_0-rmse:39.54075\tvalidation_0-root_mean_squared_error:39.54075\n",
      "[2800]\tvalidation_0-rmse:39.53334\tvalidation_0-root_mean_squared_error:39.53334\n",
      "[2900]\tvalidation_0-rmse:39.52310\tvalidation_0-root_mean_squared_error:39.52310\n",
      "[3000]\tvalidation_0-rmse:39.50969\tvalidation_0-root_mean_squared_error:39.50969\n",
      "[3100]\tvalidation_0-rmse:39.49135\tvalidation_0-root_mean_squared_error:39.49135\n",
      "[3200]\tvalidation_0-rmse:39.47893\tvalidation_0-root_mean_squared_error:39.47893\n",
      "[3300]\tvalidation_0-rmse:39.47546\tvalidation_0-root_mean_squared_error:39.47546\n",
      "[3400]\tvalidation_0-rmse:39.46824\tvalidation_0-root_mean_squared_error:39.46824\n",
      "[3500]\tvalidation_0-rmse:39.45496\tvalidation_0-root_mean_squared_error:39.45496\n",
      "[3600]\tvalidation_0-rmse:39.44522\tvalidation_0-root_mean_squared_error:39.44522\n",
      "[3700]\tvalidation_0-rmse:39.43554\tvalidation_0-root_mean_squared_error:39.43554\n",
      "[3800]\tvalidation_0-rmse:39.41364\tvalidation_0-root_mean_squared_error:39.41363\n",
      "[3900]\tvalidation_0-rmse:39.39158\tvalidation_0-root_mean_squared_error:39.39158\n",
      "[4000]\tvalidation_0-rmse:39.38294\tvalidation_0-root_mean_squared_error:39.38295\n",
      "[4100]\tvalidation_0-rmse:39.36906\tvalidation_0-root_mean_squared_error:39.36906\n",
      "[4200]\tvalidation_0-rmse:39.35844\tvalidation_0-root_mean_squared_error:39.35844\n",
      "[4300]\tvalidation_0-rmse:39.34246\tvalidation_0-root_mean_squared_error:39.34246\n",
      "[4400]\tvalidation_0-rmse:39.32275\tvalidation_0-root_mean_squared_error:39.32275\n",
      "[4500]\tvalidation_0-rmse:39.32744\tvalidation_0-root_mean_squared_error:39.32744\n",
      "[4600]\tvalidation_0-rmse:39.32737\tvalidation_0-root_mean_squared_error:39.32737\n",
      "[4700]\tvalidation_0-rmse:39.33073\tvalidation_0-root_mean_squared_error:39.33073\n",
      "[4800]\tvalidation_0-rmse:39.32244\tvalidation_0-root_mean_squared_error:39.32243\n",
      "[4900]\tvalidation_0-rmse:39.32736\tvalidation_0-root_mean_squared_error:39.32737\n",
      "[4967]\tvalidation_0-rmse:39.33121\tvalidation_0-root_mean_squared_error:39.33122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [11:02, 212.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1571\n",
      "[LightGBM] [Info] Number of data points in the train set: 3475, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 157.237122\n",
      "0:\tlearn: 60.6014303\ttest: 60.7946485\tbest: 60.7946485 (0)\ttotal: 18.6ms\tremaining: 3m 6s\n",
      "100:\tlearn: 45.1270455\ttest: 46.8539846\tbest: 46.8539846 (100)\ttotal: 2.21s\tremaining: 3m 37s\n",
      "200:\tlearn: 38.8983723\ttest: 42.3812053\tbest: 42.3812053 (200)\ttotal: 5.18s\tremaining: 4m 12s\n",
      "300:\tlearn: 35.4510649\ttest: 40.6666022\tbest: 40.6666022 (300)\ttotal: 8.26s\tremaining: 4m 26s\n",
      "400:\tlearn: 33.2082143\ttest: 39.8262530\tbest: 39.8262530 (400)\ttotal: 11.4s\tremaining: 4m 32s\n",
      "500:\tlearn: 31.5916940\ttest: 39.3422105\tbest: 39.3422105 (500)\ttotal: 14.3s\tremaining: 4m 30s\n",
      "600:\tlearn: 30.3353372\ttest: 39.0297971\tbest: 39.0297971 (600)\ttotal: 17.1s\tremaining: 4m 27s\n",
      "700:\tlearn: 29.1521855\ttest: 38.7589983\tbest: 38.7589983 (700)\ttotal: 20.3s\tremaining: 4m 28s\n",
      "800:\tlearn: 28.0347992\ttest: 38.5510221\tbest: 38.5510221 (800)\ttotal: 22.9s\tremaining: 4m 23s\n",
      "900:\tlearn: 27.1562471\ttest: 38.3687485\tbest: 38.3687485 (900)\ttotal: 25.7s\tremaining: 4m 19s\n",
      "1000:\tlearn: 26.4581270\ttest: 38.2381800\tbest: 38.2381243 (999)\ttotal: 28.7s\tremaining: 4m 17s\n",
      "1100:\tlearn: 25.5854458\ttest: 38.1137031\tbest: 38.1137031 (1100)\ttotal: 31.6s\tremaining: 4m 15s\n",
      "1200:\tlearn: 24.7689243\ttest: 37.9843686\tbest: 37.9832513 (1199)\ttotal: 34.9s\tremaining: 4m 15s\n",
      "1300:\tlearn: 23.9321596\ttest: 37.8767000\tbest: 37.8767000 (1300)\ttotal: 38.3s\tremaining: 4m 16s\n",
      "1400:\tlearn: 23.1616032\ttest: 37.7823674\tbest: 37.7804230 (1397)\ttotal: 41.5s\tremaining: 4m 14s\n",
      "1500:\tlearn: 22.4709566\ttest: 37.7061162\tbest: 37.7061162 (1500)\ttotal: 44.5s\tremaining: 4m 12s\n",
      "1600:\tlearn: 21.8346453\ttest: 37.6415297\tbest: 37.6415297 (1600)\ttotal: 47.5s\tremaining: 4m 9s\n",
      "1700:\tlearn: 21.2163242\ttest: 37.5639627\tbest: 37.5608589 (1691)\ttotal: 50.6s\tremaining: 4m 6s\n",
      "1800:\tlearn: 20.6386361\ttest: 37.4895171\tbest: 37.4893970 (1794)\ttotal: 53.7s\tremaining: 4m 4s\n",
      "1900:\tlearn: 20.1191764\ttest: 37.4305222\tbest: 37.4304886 (1898)\ttotal: 56.8s\tremaining: 4m 1s\n",
      "2000:\tlearn: 19.5755088\ttest: 37.3771629\tbest: 37.3770653 (1999)\ttotal: 59.9s\tremaining: 3m 59s\n",
      "2100:\tlearn: 19.1370312\ttest: 37.3111661\tbest: 37.3111661 (2100)\ttotal: 1m 3s\tremaining: 3m 58s\n",
      "2200:\tlearn: 18.6629781\ttest: 37.2623255\tbest: 37.2616874 (2199)\ttotal: 1m 6s\tremaining: 3m 56s\n",
      "2300:\tlearn: 18.1769420\ttest: 37.2325255\tbest: 37.2325255 (2300)\ttotal: 1m 9s\tremaining: 3m 54s\n",
      "2400:\tlearn: 17.7596631\ttest: 37.1827632\tbest: 37.1827632 (2400)\ttotal: 1m 13s\tremaining: 3m 52s\n",
      "2500:\tlearn: 17.3478407\ttest: 37.1452628\tbest: 37.1452628 (2500)\ttotal: 1m 16s\tremaining: 3m 50s\n",
      "2600:\tlearn: 16.9706992\ttest: 37.1098731\tbest: 37.1087662 (2590)\ttotal: 1m 20s\tremaining: 3m 47s\n",
      "2700:\tlearn: 16.5905001\ttest: 37.0705512\tbest: 37.0692389 (2698)\ttotal: 1m 23s\tremaining: 3m 45s\n",
      "2800:\tlearn: 16.2140805\ttest: 37.0445987\tbest: 37.0445987 (2800)\ttotal: 1m 26s\tremaining: 3m 42s\n",
      "2900:\tlearn: 15.8330971\ttest: 37.0122717\tbest: 37.0116863 (2896)\ttotal: 1m 29s\tremaining: 3m 39s\n",
      "3000:\tlearn: 15.5329802\ttest: 36.9897535\tbest: 36.9877548 (2995)\ttotal: 1m 33s\tremaining: 3m 38s\n",
      "3100:\tlearn: 15.1945900\ttest: 36.9671946\tbest: 36.9666859 (3098)\ttotal: 1m 37s\tremaining: 3m 36s\n",
      "3200:\tlearn: 14.8775292\ttest: 36.9442438\tbest: 36.9441853 (3199)\ttotal: 1m 40s\tremaining: 3m 34s\n",
      "3300:\tlearn: 14.5613022\ttest: 36.9241415\tbest: 36.9241415 (3300)\ttotal: 1m 44s\tremaining: 3m 31s\n",
      "3400:\tlearn: 14.2363017\ttest: 36.9021560\tbest: 36.9017708 (3398)\ttotal: 1m 47s\tremaining: 3m 29s\n",
      "3500:\tlearn: 13.9356641\ttest: 36.8777251\tbest: 36.8739158 (3487)\ttotal: 1m 51s\tremaining: 3m 26s\n",
      "3600:\tlearn: 13.6612619\ttest: 36.8573423\tbest: 36.8570430 (3597)\ttotal: 1m 54s\tremaining: 3m 23s\n",
      "3700:\tlearn: 13.4043827\ttest: 36.8364539\tbest: 36.8356163 (3688)\ttotal: 1m 57s\tremaining: 3m 20s\n",
      "3800:\tlearn: 13.1592913\ttest: 36.8279728\tbest: 36.8259537 (3795)\ttotal: 2m 1s\tremaining: 3m 17s\n",
      "3900:\tlearn: 12.8966955\ttest: 36.8007619\tbest: 36.8006865 (3898)\ttotal: 2m 4s\tremaining: 3m 14s\n",
      "4000:\tlearn: 12.6652655\ttest: 36.7929796\tbest: 36.7929771 (3999)\ttotal: 2m 7s\tremaining: 3m 11s\n",
      "4100:\tlearn: 12.4538106\ttest: 36.7900857\tbest: 36.7891689 (4072)\ttotal: 2m 10s\tremaining: 3m 8s\n",
      "4200:\tlearn: 12.2412203\ttest: 36.7742643\tbest: 36.7742643 (4200)\ttotal: 2m 14s\tremaining: 3m 5s\n",
      "4300:\tlearn: 12.0506642\ttest: 36.7644039\tbest: 36.7644039 (4300)\ttotal: 2m 17s\tremaining: 3m 2s\n",
      "4400:\tlearn: 11.8237068\ttest: 36.7501552\tbest: 36.7501552 (4400)\ttotal: 2m 21s\tremaining: 2m 59s\n",
      "4500:\tlearn: 11.6213539\ttest: 36.7385301\tbest: 36.7385031 (4498)\ttotal: 2m 24s\tremaining: 2m 56s\n",
      "4600:\tlearn: 11.4329248\ttest: 36.7281049\tbest: 36.7280531 (4599)\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "4700:\tlearn: 11.2219926\ttest: 36.7240127\tbest: 36.7240127 (4700)\ttotal: 2m 31s\tremaining: 2m 50s\n",
      "4800:\tlearn: 11.0282549\ttest: 36.7120584\tbest: 36.7119876 (4799)\ttotal: 2m 34s\tremaining: 2m 47s\n",
      "4900:\tlearn: 10.8276526\ttest: 36.7074969\tbest: 36.7063736 (4878)\ttotal: 2m 37s\tremaining: 2m 43s\n",
      "5000:\tlearn: 10.6436831\ttest: 36.7028296\tbest: 36.7028296 (5000)\ttotal: 2m 40s\tremaining: 2m 40s\n",
      "5100:\tlearn: 10.4580773\ttest: 36.7051562\tbest: 36.7002875 (5040)\ttotal: 2m 43s\tremaining: 2m 37s\n",
      "5200:\tlearn: 10.2866869\ttest: 36.6951654\tbest: 36.6947332 (5177)\ttotal: 2m 47s\tremaining: 2m 34s\n",
      "5300:\tlearn: 10.1162651\ttest: 36.6919478\tbest: 36.6910710 (5238)\ttotal: 2m 50s\tremaining: 2m 30s\n",
      "5400:\tlearn: 9.9255600\ttest: 36.6845726\tbest: 36.6830585 (5393)\ttotal: 2m 53s\tremaining: 2m 27s\n",
      "5500:\tlearn: 9.7605600\ttest: 36.6798339\tbest: 36.6798339 (5500)\ttotal: 2m 56s\tremaining: 2m 24s\n",
      "5600:\tlearn: 9.5849614\ttest: 36.6788941\tbest: 36.6775012 (5578)\ttotal: 2m 59s\tremaining: 2m 21s\n",
      "5700:\tlearn: 9.4401822\ttest: 36.6712281\tbest: 36.6712192 (5695)\ttotal: 3m 3s\tremaining: 2m 18s\n",
      "5800:\tlearn: 9.2909468\ttest: 36.6688823\tbest: 36.6671639 (5762)\ttotal: 3m 6s\tremaining: 2m 15s\n",
      "5900:\tlearn: 9.1345595\ttest: 36.6641962\tbest: 36.6641962 (5900)\ttotal: 3m 9s\tremaining: 2m 11s\n",
      "6000:\tlearn: 8.9934418\ttest: 36.6576015\tbest: 36.6576015 (6000)\ttotal: 3m 13s\tremaining: 2m 8s\n",
      "6100:\tlearn: 8.8556960\ttest: 36.6557343\tbest: 36.6555999 (6088)\ttotal: 3m 16s\tremaining: 2m 5s\n",
      "6200:\tlearn: 8.7082846\ttest: 36.6491212\tbest: 36.6477071 (6175)\ttotal: 3m 19s\tremaining: 2m 2s\n",
      "6300:\tlearn: 8.5845584\ttest: 36.6484202\tbest: 36.6467004 (6293)\ttotal: 3m 23s\tremaining: 1m 59s\n",
      "6400:\tlearn: 8.4465218\ttest: 36.6428712\tbest: 36.6425464 (6391)\ttotal: 3m 26s\tremaining: 1m 56s\n",
      "6500:\tlearn: 8.3383799\ttest: 36.6434288\tbest: 36.6408927 (6450)\ttotal: 3m 29s\tremaining: 1m 52s\n",
      "6600:\tlearn: 8.2067574\ttest: 36.6416601\tbest: 36.6408927 (6450)\ttotal: 3m 33s\tremaining: 1m 49s\n",
      "6700:\tlearn: 8.1085612\ttest: 36.6354320\tbest: 36.6353304 (6696)\ttotal: 3m 36s\tremaining: 1m 46s\n",
      "6800:\tlearn: 7.9783983\ttest: 36.6277310\tbest: 36.6277019 (6793)\ttotal: 3m 39s\tremaining: 1m 43s\n",
      "6900:\tlearn: 7.8622867\ttest: 36.6180207\tbest: 36.6168844 (6871)\ttotal: 3m 42s\tremaining: 1m 40s\n",
      "7000:\tlearn: 7.7595229\ttest: 36.6150327\tbest: 36.6146303 (6995)\ttotal: 3m 46s\tremaining: 1m 36s\n",
      "7100:\tlearn: 7.6438598\ttest: 36.6132803\tbest: 36.6123065 (7081)\ttotal: 3m 50s\tremaining: 1m 33s\n",
      "7200:\tlearn: 7.5437654\ttest: 36.6130693\tbest: 36.6119776 (7177)\ttotal: 3m 53s\tremaining: 1m 30s\n",
      "7300:\tlearn: 7.4424097\ttest: 36.6130795\tbest: 36.6119776 (7177)\ttotal: 3m 56s\tremaining: 1m 27s\n",
      "7400:\tlearn: 7.3409543\ttest: 36.6133176\tbest: 36.6119776 (7177)\ttotal: 3m 59s\tremaining: 1m 24s\n",
      "7500:\tlearn: 7.2486599\ttest: 36.6141752\tbest: 36.6117319 (7436)\ttotal: 4m 2s\tremaining: 1m 20s\n",
      "7600:\tlearn: 7.1411690\ttest: 36.6162373\tbest: 36.6117319 (7436)\ttotal: 4m 5s\tremaining: 1m 17s\n",
      "7700:\tlearn: 7.0611614\ttest: 36.6144467\tbest: 36.6117319 (7436)\ttotal: 4m 8s\tremaining: 1m 14s\n",
      "7800:\tlearn: 6.9782858\ttest: 36.6091764\tbest: 36.6090810 (7799)\ttotal: 4m 11s\tremaining: 1m 10s\n",
      "7900:\tlearn: 6.8817452\ttest: 36.6100062\tbest: 36.6079320 (7808)\ttotal: 4m 14s\tremaining: 1m 7s\n",
      "8000:\tlearn: 6.8060696\ttest: 36.6074395\tbest: 36.6065773 (7990)\ttotal: 4m 17s\tremaining: 1m 4s\n",
      "8100:\tlearn: 6.7174440\ttest: 36.6079275\tbest: 36.6060937 (8067)\ttotal: 4m 20s\tremaining: 1m 1s\n",
      "8200:\tlearn: 6.6493731\ttest: 36.6066963\tbest: 36.6060937 (8067)\ttotal: 4m 24s\tremaining: 57.9s\n",
      "8300:\tlearn: 6.5426920\ttest: 36.6095680\tbest: 36.6053740 (8226)\ttotal: 4m 27s\tremaining: 54.7s\n",
      "8400:\tlearn: 6.4476049\ttest: 36.6120389\tbest: 36.6053740 (8226)\ttotal: 4m 30s\tremaining: 51.5s\n",
      "8500:\tlearn: 6.3598182\ttest: 36.6132598\tbest: 36.6053740 (8226)\ttotal: 4m 33s\tremaining: 48.2s\n",
      "8600:\tlearn: 6.2712663\ttest: 36.6117379\tbest: 36.6053740 (8226)\ttotal: 4m 36s\tremaining: 45s\n",
      "8700:\tlearn: 6.1709494\ttest: 36.6095297\tbest: 36.6053740 (8226)\ttotal: 4m 40s\tremaining: 41.8s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 36.60537396\n",
      "bestIteration = 8226\n",
      "\n",
      "Shrink model to first 8227 iterations.\n",
      "[0]\tvalidation_0-rmse:60.77724\tvalidation_0-root_mean_squared_error:60.77724\n",
      "[100]\tvalidation_0-rmse:46.89625\tvalidation_0-root_mean_squared_error:46.89625\n",
      "[200]\tvalidation_0-rmse:43.15537\tvalidation_0-root_mean_squared_error:43.15538\n",
      "[300]\tvalidation_0-rmse:41.64008\tvalidation_0-root_mean_squared_error:41.64008\n",
      "[400]\tvalidation_0-rmse:40.82778\tvalidation_0-root_mean_squared_error:40.82778\n",
      "[500]\tvalidation_0-rmse:40.26208\tvalidation_0-root_mean_squared_error:40.26208\n",
      "[600]\tvalidation_0-rmse:39.93237\tvalidation_0-root_mean_squared_error:39.93237\n",
      "[700]\tvalidation_0-rmse:39.73795\tvalidation_0-root_mean_squared_error:39.73795\n",
      "[800]\tvalidation_0-rmse:39.59748\tvalidation_0-root_mean_squared_error:39.59748\n",
      "[900]\tvalidation_0-rmse:39.47073\tvalidation_0-root_mean_squared_error:39.47073\n",
      "[1000]\tvalidation_0-rmse:39.39821\tvalidation_0-root_mean_squared_error:39.39820\n",
      "[1100]\tvalidation_0-rmse:39.32234\tvalidation_0-root_mean_squared_error:39.32234\n",
      "[1200]\tvalidation_0-rmse:39.25261\tvalidation_0-root_mean_squared_error:39.25261\n",
      "[1300]\tvalidation_0-rmse:39.18237\tvalidation_0-root_mean_squared_error:39.18237\n",
      "[1400]\tvalidation_0-rmse:39.09624\tvalidation_0-root_mean_squared_error:39.09624\n",
      "[1500]\tvalidation_0-rmse:39.01617\tvalidation_0-root_mean_squared_error:39.01617\n",
      "[1600]\tvalidation_0-rmse:38.95396\tvalidation_0-root_mean_squared_error:38.95396\n",
      "[1700]\tvalidation_0-rmse:38.89642\tvalidation_0-root_mean_squared_error:38.89642\n",
      "[1800]\tvalidation_0-rmse:38.85772\tvalidation_0-root_mean_squared_error:38.85772\n",
      "[1900]\tvalidation_0-rmse:38.83309\tvalidation_0-root_mean_squared_error:38.83309\n",
      "[2000]\tvalidation_0-rmse:38.78374\tvalidation_0-root_mean_squared_error:38.78375\n",
      "[2100]\tvalidation_0-rmse:38.73477\tvalidation_0-root_mean_squared_error:38.73478\n",
      "[2200]\tvalidation_0-rmse:38.66559\tvalidation_0-root_mean_squared_error:38.66559\n",
      "[2300]\tvalidation_0-rmse:38.61821\tvalidation_0-root_mean_squared_error:38.61821\n",
      "[2400]\tvalidation_0-rmse:38.55106\tvalidation_0-root_mean_squared_error:38.55106\n",
      "[2500]\tvalidation_0-rmse:38.48215\tvalidation_0-root_mean_squared_error:38.48215\n",
      "[2600]\tvalidation_0-rmse:38.42738\tvalidation_0-root_mean_squared_error:38.42738\n",
      "[2700]\tvalidation_0-rmse:38.36923\tvalidation_0-root_mean_squared_error:38.36923\n",
      "[2800]\tvalidation_0-rmse:38.31690\tvalidation_0-root_mean_squared_error:38.31690\n",
      "[2900]\tvalidation_0-rmse:38.27694\tvalidation_0-root_mean_squared_error:38.27694\n",
      "[3000]\tvalidation_0-rmse:38.25047\tvalidation_0-root_mean_squared_error:38.25047\n",
      "[3100]\tvalidation_0-rmse:38.22885\tvalidation_0-root_mean_squared_error:38.22885\n",
      "[3200]\tvalidation_0-rmse:38.20527\tvalidation_0-root_mean_squared_error:38.20527\n",
      "[3300]\tvalidation_0-rmse:38.17581\tvalidation_0-root_mean_squared_error:38.17581\n",
      "[3400]\tvalidation_0-rmse:38.14680\tvalidation_0-root_mean_squared_error:38.14680\n",
      "[3500]\tvalidation_0-rmse:38.11964\tvalidation_0-root_mean_squared_error:38.11964\n",
      "[3600]\tvalidation_0-rmse:38.09463\tvalidation_0-root_mean_squared_error:38.09463\n",
      "[3700]\tvalidation_0-rmse:38.06563\tvalidation_0-root_mean_squared_error:38.06563\n",
      "[3800]\tvalidation_0-rmse:38.03057\tvalidation_0-root_mean_squared_error:38.03057\n",
      "[3900]\tvalidation_0-rmse:38.02334\tvalidation_0-root_mean_squared_error:38.02334\n",
      "[4000]\tvalidation_0-rmse:38.00524\tvalidation_0-root_mean_squared_error:38.00524\n",
      "[4100]\tvalidation_0-rmse:37.99787\tvalidation_0-root_mean_squared_error:37.99788\n",
      "[4200]\tvalidation_0-rmse:37.98154\tvalidation_0-root_mean_squared_error:37.98154\n",
      "[4300]\tvalidation_0-rmse:37.97669\tvalidation_0-root_mean_squared_error:37.97669\n",
      "[4400]\tvalidation_0-rmse:37.97089\tvalidation_0-root_mean_squared_error:37.97089\n",
      "[4500]\tvalidation_0-rmse:37.96503\tvalidation_0-root_mean_squared_error:37.96503\n",
      "[4600]\tvalidation_0-rmse:37.93792\tvalidation_0-root_mean_squared_error:37.93792\n",
      "[4700]\tvalidation_0-rmse:37.94396\tvalidation_0-root_mean_squared_error:37.94396\n",
      "[4800]\tvalidation_0-rmse:37.93610\tvalidation_0-root_mean_squared_error:37.93610\n",
      "[4900]\tvalidation_0-rmse:37.94187\tvalidation_0-root_mean_squared_error:37.94187\n",
      "[5000]\tvalidation_0-rmse:37.93777\tvalidation_0-root_mean_squared_error:37.93777\n",
      "[5100]\tvalidation_0-rmse:37.94636\tvalidation_0-root_mean_squared_error:37.94636\n",
      "[5116]\tvalidation_0-rmse:37.94590\tvalidation_0-root_mean_squared_error:37.94590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [16:02, 246.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1560\n",
      "[LightGBM] [Info] Number of data points in the train set: 3475, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 157.063309\n",
      "0:\tlearn: 60.6063864\ttest: 60.8112299\tbest: 60.8112299 (0)\ttotal: 16.8ms\tremaining: 2m 47s\n",
      "100:\tlearn: 44.6720446\ttest: 47.5307961\tbest: 47.5307961 (100)\ttotal: 2.31s\tremaining: 3m 46s\n",
      "200:\tlearn: 38.3069288\ttest: 43.9226278\tbest: 43.9226278 (200)\ttotal: 5.01s\tremaining: 4m 4s\n",
      "300:\tlearn: 34.8000820\ttest: 42.5284960\tbest: 42.5284960 (300)\ttotal: 7.76s\tremaining: 4m 10s\n",
      "400:\tlearn: 32.6221258\ttest: 41.9003158\tbest: 41.9003158 (400)\ttotal: 10.4s\tremaining: 4m 10s\n",
      "500:\tlearn: 31.0140313\ttest: 41.4877224\tbest: 41.4877224 (500)\ttotal: 13.1s\tremaining: 4m 8s\n",
      "600:\tlearn: 29.6661111\ttest: 41.2052206\tbest: 41.2052206 (600)\ttotal: 15.7s\tremaining: 4m 5s\n",
      "700:\tlearn: 28.4412860\ttest: 40.9896129\tbest: 40.9896129 (700)\ttotal: 18.6s\tremaining: 4m 7s\n",
      "800:\tlearn: 27.3865312\ttest: 40.8010040\tbest: 40.8010040 (800)\ttotal: 21.6s\tremaining: 4m 7s\n",
      "900:\tlearn: 26.3695772\ttest: 40.6661726\tbest: 40.6661726 (900)\ttotal: 24.6s\tremaining: 4m 8s\n",
      "1000:\tlearn: 25.4944457\ttest: 40.5329138\tbest: 40.5329138 (1000)\ttotal: 27.7s\tremaining: 4m 9s\n",
      "1100:\tlearn: 24.6654174\ttest: 40.4208060\tbest: 40.4208060 (1100)\ttotal: 30.8s\tremaining: 4m 8s\n",
      "1200:\tlearn: 23.9210927\ttest: 40.3198583\tbest: 40.3198583 (1200)\ttotal: 33.9s\tremaining: 4m 8s\n",
      "1300:\tlearn: 23.2495474\ttest: 40.2524222\tbest: 40.2524222 (1300)\ttotal: 37s\tremaining: 4m 7s\n",
      "1400:\tlearn: 22.6657511\ttest: 40.1849786\tbest: 40.1845274 (1399)\ttotal: 40.1s\tremaining: 4m 5s\n",
      "1500:\tlearn: 22.0363863\ttest: 40.1088362\tbest: 40.1072356 (1493)\ttotal: 43.2s\tremaining: 4m 4s\n",
      "1600:\tlearn: 21.4928818\ttest: 40.0679019\tbest: 40.0668821 (1598)\ttotal: 46.3s\tremaining: 4m 2s\n",
      "1700:\tlearn: 20.8924147\ttest: 40.0326244\tbest: 40.0321520 (1699)\ttotal: 49.3s\tremaining: 4m\n",
      "1800:\tlearn: 20.3589957\ttest: 40.0035112\tbest: 40.0035112 (1800)\ttotal: 52.4s\tremaining: 3m 58s\n",
      "1900:\tlearn: 19.8502355\ttest: 39.9703430\tbest: 39.9692959 (1897)\ttotal: 55.5s\tremaining: 3m 56s\n",
      "2000:\tlearn: 19.3351318\ttest: 39.9424837\tbest: 39.9412404 (1998)\ttotal: 58.6s\tremaining: 3m 54s\n",
      "2100:\tlearn: 18.8080377\ttest: 39.9153689\tbest: 39.9145173 (2082)\ttotal: 1m 1s\tremaining: 3m 51s\n",
      "2200:\tlearn: 18.3163152\ttest: 39.8927063\tbest: 39.8921618 (2199)\ttotal: 1m 4s\tremaining: 3m 48s\n",
      "2300:\tlearn: 17.8771159\ttest: 39.8777589\tbest: 39.8764787 (2295)\ttotal: 1m 7s\tremaining: 3m 45s\n",
      "2400:\tlearn: 17.4704234\ttest: 39.8559078\tbest: 39.8559078 (2400)\ttotal: 1m 10s\tremaining: 3m 43s\n",
      "2500:\tlearn: 17.0985161\ttest: 39.8401638\tbest: 39.8389413 (2495)\ttotal: 1m 13s\tremaining: 3m 40s\n",
      "2600:\tlearn: 16.7266392\ttest: 39.8292438\tbest: 39.8238595 (2564)\ttotal: 1m 16s\tremaining: 3m 37s\n",
      "2700:\tlearn: 16.4260121\ttest: 39.8067196\tbest: 39.8064259 (2699)\ttotal: 1m 19s\tremaining: 3m 35s\n",
      "2800:\tlearn: 16.0832016\ttest: 39.8049937\tbest: 39.8036981 (2736)\ttotal: 1m 22s\tremaining: 3m 32s\n",
      "2900:\tlearn: 15.7447946\ttest: 39.7824535\tbest: 39.7824535 (2900)\ttotal: 1m 25s\tremaining: 3m 29s\n",
      "3000:\tlearn: 15.4631316\ttest: 39.7755039\tbest: 39.7727452 (2962)\ttotal: 1m 28s\tremaining: 3m 26s\n",
      "3100:\tlearn: 15.1331150\ttest: 39.7617164\tbest: 39.7584059 (3096)\ttotal: 1m 31s\tremaining: 3m 24s\n",
      "3200:\tlearn: 14.8175123\ttest: 39.7530343\tbest: 39.7512669 (3191)\ttotal: 1m 34s\tremaining: 3m 21s\n",
      "3300:\tlearn: 14.5607993\ttest: 39.7415987\tbest: 39.7395083 (3289)\ttotal: 1m 37s\tremaining: 3m 18s\n",
      "3400:\tlearn: 14.3053864\ttest: 39.7322770\tbest: 39.7299707 (3387)\ttotal: 1m 40s\tremaining: 3m 15s\n",
      "3500:\tlearn: 14.0405854\ttest: 39.7358312\tbest: 39.7299707 (3387)\ttotal: 1m 44s\tremaining: 3m 13s\n",
      "3600:\tlearn: 13.7844881\ttest: 39.7234220\tbest: 39.7232956 (3599)\ttotal: 1m 47s\tremaining: 3m 10s\n",
      "3700:\tlearn: 13.5388397\ttest: 39.7169363\tbest: 39.7163776 (3692)\ttotal: 1m 50s\tremaining: 3m 8s\n",
      "3800:\tlearn: 13.2948743\ttest: 39.7005974\tbest: 39.7005974 (3800)\ttotal: 1m 53s\tremaining: 3m 5s\n",
      "3900:\tlearn: 13.0795317\ttest: 39.6926118\tbest: 39.6915664 (3878)\ttotal: 1m 57s\tremaining: 3m 3s\n",
      "4000:\tlearn: 12.8121942\ttest: 39.6803337\tbest: 39.6789800 (3997)\ttotal: 2m\tremaining: 3m\n",
      "4100:\tlearn: 12.5744572\ttest: 39.6694966\tbest: 39.6671058 (4085)\ttotal: 2m 3s\tremaining: 2m 58s\n",
      "4200:\tlearn: 12.3251882\ttest: 39.6587469\tbest: 39.6587469 (4200)\ttotal: 2m 7s\tremaining: 2m 55s\n",
      "4300:\tlearn: 12.1203713\ttest: 39.6490817\tbest: 39.6488021 (4299)\ttotal: 2m 10s\tremaining: 2m 52s\n",
      "4400:\tlearn: 11.9172773\ttest: 39.6468780\tbest: 39.6432161 (4378)\ttotal: 2m 13s\tremaining: 2m 49s\n",
      "4500:\tlearn: 11.7291004\ttest: 39.6408746\tbest: 39.6392720 (4484)\ttotal: 2m 16s\tremaining: 2m 46s\n",
      "4600:\tlearn: 11.5792807\ttest: 39.6282836\tbest: 39.6272665 (4590)\ttotal: 2m 19s\tremaining: 2m 43s\n",
      "4700:\tlearn: 11.3971385\ttest: 39.6196472\tbest: 39.6192772 (4699)\ttotal: 2m 22s\tremaining: 2m 40s\n",
      "4800:\tlearn: 11.2130762\ttest: 39.6212943\tbest: 39.6164259 (4749)\ttotal: 2m 25s\tremaining: 2m 37s\n",
      "4900:\tlearn: 11.0606021\ttest: 39.6213574\tbest: 39.6164259 (4749)\ttotal: 2m 28s\tremaining: 2m 34s\n",
      "5000:\tlearn: 10.8934379\ttest: 39.6223915\tbest: 39.6164259 (4749)\ttotal: 2m 31s\tremaining: 2m 31s\n",
      "5100:\tlearn: 10.7453762\ttest: 39.6145881\tbest: 39.6145881 (5100)\ttotal: 2m 35s\tremaining: 2m 29s\n",
      "5200:\tlearn: 10.5868590\ttest: 39.6087224\tbest: 39.6067839 (5165)\ttotal: 2m 38s\tremaining: 2m 25s\n",
      "5300:\tlearn: 10.4348238\ttest: 39.5983396\tbest: 39.5979970 (5295)\ttotal: 2m 41s\tremaining: 2m 22s\n",
      "5400:\tlearn: 10.2947938\ttest: 39.5981664\tbest: 39.5964013 (5340)\ttotal: 2m 44s\tremaining: 2m 19s\n",
      "5500:\tlearn: 10.1540803\ttest: 39.5937699\tbest: 39.5924321 (5494)\ttotal: 2m 47s\tremaining: 2m 16s\n",
      "5600:\tlearn: 9.9964629\ttest: 39.5804173\tbest: 39.5804173 (5600)\ttotal: 2m 50s\tremaining: 2m 13s\n",
      "5700:\tlearn: 9.8487088\ttest: 39.5789122\tbest: 39.5773597 (5697)\ttotal: 2m 53s\tremaining: 2m 10s\n",
      "5800:\tlearn: 9.6872942\ttest: 39.5753648\tbest: 39.5742540 (5790)\ttotal: 2m 56s\tremaining: 2m 7s\n",
      "5900:\tlearn: 9.5361191\ttest: 39.5743097\tbest: 39.5727834 (5891)\ttotal: 2m 59s\tremaining: 2m 4s\n",
      "6000:\tlearn: 9.3871212\ttest: 39.5775732\tbest: 39.5727834 (5891)\ttotal: 3m 2s\tremaining: 2m 1s\n",
      "6100:\tlearn: 9.2554984\ttest: 39.5712648\tbest: 39.5708367 (6097)\ttotal: 3m 5s\tremaining: 1m 58s\n",
      "6200:\tlearn: 9.1247337\ttest: 39.5678119\tbest: 39.5675766 (6197)\ttotal: 3m 8s\tremaining: 1m 55s\n",
      "6300:\tlearn: 8.9855996\ttest: 39.5646332\tbest: 39.5609046 (6268)\ttotal: 3m 11s\tremaining: 1m 52s\n",
      "6400:\tlearn: 8.8320171\ttest: 39.5660045\tbest: 39.5609046 (6268)\ttotal: 3m 15s\tremaining: 1m 49s\n",
      "6500:\tlearn: 8.6970113\ttest: 39.5633008\tbest: 39.5609046 (6268)\ttotal: 3m 18s\tremaining: 1m 46s\n",
      "6600:\tlearn: 8.5829360\ttest: 39.5605064\tbest: 39.5599242 (6549)\ttotal: 3m 21s\tremaining: 1m 43s\n",
      "6700:\tlearn: 8.4740671\ttest: 39.5615909\tbest: 39.5595339 (6603)\ttotal: 3m 25s\tremaining: 1m 40s\n",
      "6800:\tlearn: 8.3638932\ttest: 39.5567114\tbest: 39.5567114 (6800)\ttotal: 3m 28s\tremaining: 1m 37s\n",
      "6900:\tlearn: 8.2373865\ttest: 39.5526488\tbest: 39.5520939 (6861)\ttotal: 3m 31s\tremaining: 1m 34s\n",
      "7000:\tlearn: 8.1109364\ttest: 39.5499706\tbest: 39.5491694 (6995)\ttotal: 3m 34s\tremaining: 1m 32s\n",
      "7100:\tlearn: 7.9870671\ttest: 39.5487008\tbest: 39.5483823 (7086)\ttotal: 3m 38s\tremaining: 1m 29s\n",
      "7200:\tlearn: 7.8650595\ttest: 39.5471811\tbest: 39.5456337 (7161)\ttotal: 3m 41s\tremaining: 1m 26s\n",
      "7300:\tlearn: 7.7460955\ttest: 39.5481905\tbest: 39.5456337 (7161)\ttotal: 3m 44s\tremaining: 1m 23s\n",
      "7400:\tlearn: 7.6515868\ttest: 39.5463280\tbest: 39.5436026 (7368)\ttotal: 3m 47s\tremaining: 1m 20s\n",
      "7500:\tlearn: 7.5375922\ttest: 39.5457643\tbest: 39.5436026 (7368)\ttotal: 3m 51s\tremaining: 1m 17s\n",
      "7600:\tlearn: 7.4381846\ttest: 39.5407856\tbest: 39.5398022 (7594)\ttotal: 3m 54s\tremaining: 1m 13s\n",
      "7700:\tlearn: 7.3109353\ttest: 39.5421525\tbest: 39.5380432 (7620)\ttotal: 3m 57s\tremaining: 1m 10s\n",
      "7800:\tlearn: 7.2218021\ttest: 39.5435488\tbest: 39.5380432 (7620)\ttotal: 4m\tremaining: 1m 7s\n",
      "7900:\tlearn: 7.1215532\ttest: 39.5445210\tbest: 39.5380432 (7620)\ttotal: 4m 3s\tremaining: 1m 4s\n",
      "8000:\tlearn: 7.0177164\ttest: 39.5428653\tbest: 39.5380432 (7620)\ttotal: 4m 6s\tremaining: 1m 1s\n",
      "8100:\tlearn: 6.9113297\ttest: 39.5453725\tbest: 39.5380432 (7620)\ttotal: 4m 9s\tremaining: 58.5s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 39.53804322\n",
      "bestIteration = 7620\n",
      "\n",
      "Shrink model to first 7621 iterations.\n",
      "[0]\tvalidation_0-rmse:60.80225\tvalidation_0-root_mean_squared_error:60.80225\n",
      "[100]\tvalidation_0-rmse:48.18373\tvalidation_0-root_mean_squared_error:48.18373\n",
      "[200]\tvalidation_0-rmse:44.82792\tvalidation_0-root_mean_squared_error:44.82793\n",
      "[300]\tvalidation_0-rmse:43.43305\tvalidation_0-root_mean_squared_error:43.43305\n",
      "[400]\tvalidation_0-rmse:42.75253\tvalidation_0-root_mean_squared_error:42.75253\n",
      "[500]\tvalidation_0-rmse:42.43699\tvalidation_0-root_mean_squared_error:42.43698\n",
      "[600]\tvalidation_0-rmse:42.24010\tvalidation_0-root_mean_squared_error:42.24010\n",
      "[700]\tvalidation_0-rmse:42.14702\tvalidation_0-root_mean_squared_error:42.14702\n",
      "[800]\tvalidation_0-rmse:42.09019\tvalidation_0-root_mean_squared_error:42.09019\n",
      "[900]\tvalidation_0-rmse:41.98381\tvalidation_0-root_mean_squared_error:41.98381\n",
      "[1000]\tvalidation_0-rmse:41.91189\tvalidation_0-root_mean_squared_error:41.91189\n",
      "[1100]\tvalidation_0-rmse:41.84907\tvalidation_0-root_mean_squared_error:41.84907\n",
      "[1200]\tvalidation_0-rmse:41.80767\tvalidation_0-root_mean_squared_error:41.80767\n",
      "[1300]\tvalidation_0-rmse:41.78509\tvalidation_0-root_mean_squared_error:41.78509\n",
      "[1400]\tvalidation_0-rmse:41.77698\tvalidation_0-root_mean_squared_error:41.77698\n",
      "[1500]\tvalidation_0-rmse:41.76261\tvalidation_0-root_mean_squared_error:41.76261\n",
      "[1600]\tvalidation_0-rmse:41.71880\tvalidation_0-root_mean_squared_error:41.71880\n",
      "[1700]\tvalidation_0-rmse:41.68556\tvalidation_0-root_mean_squared_error:41.68556\n",
      "[1800]\tvalidation_0-rmse:41.63887\tvalidation_0-root_mean_squared_error:41.63887\n",
      "[1900]\tvalidation_0-rmse:41.59978\tvalidation_0-root_mean_squared_error:41.59978\n",
      "[2000]\tvalidation_0-rmse:41.55931\tvalidation_0-root_mean_squared_error:41.55931\n",
      "[2100]\tvalidation_0-rmse:41.51662\tvalidation_0-root_mean_squared_error:41.51662\n",
      "[2200]\tvalidation_0-rmse:41.50349\tvalidation_0-root_mean_squared_error:41.50349\n",
      "[2300]\tvalidation_0-rmse:41.47375\tvalidation_0-root_mean_squared_error:41.47375\n",
      "[2400]\tvalidation_0-rmse:41.45125\tvalidation_0-root_mean_squared_error:41.45126\n",
      "[2500]\tvalidation_0-rmse:41.42785\tvalidation_0-root_mean_squared_error:41.42785\n",
      "[2600]\tvalidation_0-rmse:41.40575\tvalidation_0-root_mean_squared_error:41.40575\n",
      "[2700]\tvalidation_0-rmse:41.38670\tvalidation_0-root_mean_squared_error:41.38671\n",
      "[2800]\tvalidation_0-rmse:41.36584\tvalidation_0-root_mean_squared_error:41.36584\n",
      "[2900]\tvalidation_0-rmse:41.34756\tvalidation_0-root_mean_squared_error:41.34756\n",
      "[3000]\tvalidation_0-rmse:41.34200\tvalidation_0-root_mean_squared_error:41.34200\n",
      "[3100]\tvalidation_0-rmse:41.33607\tvalidation_0-root_mean_squared_error:41.33607\n",
      "[3200]\tvalidation_0-rmse:41.34438\tvalidation_0-root_mean_squared_error:41.34438\n",
      "[3300]\tvalidation_0-rmse:41.34800\tvalidation_0-root_mean_squared_error:41.34800\n",
      "[3400]\tvalidation_0-rmse:41.35660\tvalidation_0-root_mean_squared_error:41.35660\n",
      "[3500]\tvalidation_0-rmse:41.34632\tvalidation_0-root_mean_squared_error:41.34632\n",
      "[3600]\tvalidation_0-rmse:41.33095\tvalidation_0-root_mean_squared_error:41.33095\n",
      "[3700]\tvalidation_0-rmse:41.33781\tvalidation_0-root_mean_squared_error:41.33781\n",
      "[3800]\tvalidation_0-rmse:41.33543\tvalidation_0-root_mean_squared_error:41.33543\n",
      "[3900]\tvalidation_0-rmse:41.33160\tvalidation_0-root_mean_squared_error:41.33160\n",
      "[4000]\tvalidation_0-rmse:41.33372\tvalidation_0-root_mean_squared_error:41.33372\n",
      "[4100]\tvalidation_0-rmse:41.33201\tvalidation_0-root_mean_squared_error:41.33201\n",
      "[4104]\tvalidation_0-rmse:41.33174\tvalidation_0-root_mean_squared_error:41.33174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [20:32, 246.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE across folds: 37.2658780105463\n",
      "Optimized weights per fold: [array([1.94166410e-21, 6.66664895e-01, 3.33335105e-01]), array([0.27943781, 0.59228564, 0.12827655]), array([4.21338586e-15, 9.53745147e-01, 4.62548533e-02]), array([0.16866705, 0.67395649, 0.15737647]), array([1.10223230e-19, 6.66576877e-01, 3.33423123e-01])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for storing results\n",
    "fold_results = []\n",
    "optimized_weights_list = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(merged_df)):\n",
    "    # Split the data\n",
    "    train_X, val_X = merged_df.iloc[train_index], merged_df.iloc[val_index]\n",
    "    train_y, val_y = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Train LightGBM\n",
    "    model1 = lgb.LGBMRegressor( # feature_fraction=0.8, bagging_fraction=0.8,\n",
    "        learning_rate=0.01, n_estimators=1000, random_state=42,\n",
    "        metric='RMSE'\n",
    "    )\n",
    "    model1.fit(train_X, train_y, eval_set=[(val_X, val_y)])\n",
    "    pred1 = model1.predict(val_X, num_iteration=model1.best_iteration_)\n",
    "\n",
    "    # Train CatBoost\n",
    "    model2 = CatBoostRegressor(\n",
    "        iterations=10000, learning_rate=0.01, depth=10, loss_function='RMSE',\n",
    "        cat_features=merged_df.select_dtypes(include=['object', 'category']).columns.to_list(),\n",
    "        verbose=100, early_stopping_rounds=500\n",
    "    )\n",
    "    model2.fit(train_X, train_y, eval_set=(val_X, val_y))\n",
    "    pred2 = model2.predict(val_X)\n",
    "    \n",
    "    # Train XGBoost\n",
    "    model3 = XGBRegressor(n_estimators=10000, learning_rate=0.01,\n",
    "        max_depth=3, random_state=42, \n",
    "        enable_categorical=True,\n",
    "        eval_metric=root_mean_squared_error,\n",
    "        early_stopping_rounds=500)\n",
    "    model3.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=100)\n",
    "    pred3 = model3.predict(val_X)\n",
    "\n",
    "    # Define loss function for weight optimization\n",
    "    def loss_function(weights):\n",
    "        w1, w2, w3 = weights\n",
    "        combined_predictions = w1 * pred1 + w2 * pred2 + w3 * pred3\n",
    "        mse = np.mean((combined_predictions - val_y) ** 2)\n",
    "        return mse\n",
    "\n",
    "    # Initial weights\n",
    "    initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "    # Constraints: weights must sum to 1\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: w[0] + w[1] + w[2] - 1}\n",
    "\n",
    "    # Bounds: weights must be between 0 and 1\n",
    "    bounds = [(0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "    # Optimize weights\n",
    "    result = minimize(loss_function, initial_weights, constraints=constraints, bounds=bounds)\n",
    "    optimized_weights = result.x\n",
    "\n",
    "    # Combine predictions using optimized weights\n",
    "    final_predictions = (\n",
    "        optimized_weights[0] * pred1 +\n",
    "        optimized_weights[1] * pred2 +\n",
    "        optimized_weights[2] * pred3\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    fold_mse = root_mean_squared_error(val_y, final_predictions)  # RMSE\n",
    "    fold_results.append(fold_mse)\n",
    "    optimized_weights_list.append(optimized_weights)\n",
    "\n",
    "# Display results\n",
    "print(f\"Average MSE across folds: {np.mean(fold_results)}\")\n",
    "print(f\"Optimized weights per fold: {optimized_weights_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08962097, 0.71064581, 0.19973322])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(optimized_weights_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1653\n",
      "[LightGBM] [Info] Number of data points in the train set: 4343, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 157.016809\n",
      "0:\tlearn: 60.6445520\ttotal: 49.6ms\tremaining: 8m 16s\n",
      "100:\tlearn: 45.0332493\ttotal: 2.28s\tremaining: 3m 43s\n",
      "200:\tlearn: 38.9044928\ttotal: 4.94s\tremaining: 4m\n",
      "300:\tlearn: 35.5399273\ttotal: 7.69s\tremaining: 4m 7s\n",
      "400:\tlearn: 33.3917089\ttotal: 10.3s\tremaining: 4m 6s\n",
      "500:\tlearn: 31.8994396\ttotal: 13.1s\tremaining: 4m 7s\n",
      "600:\tlearn: 30.7114954\ttotal: 15.9s\tremaining: 4m 8s\n",
      "700:\tlearn: 29.6846195\ttotal: 18.6s\tremaining: 4m 7s\n",
      "800:\tlearn: 28.8254993\ttotal: 21.4s\tremaining: 4m 5s\n",
      "900:\tlearn: 27.9642830\ttotal: 24.4s\tremaining: 4m 6s\n",
      "1000:\tlearn: 27.1063650\ttotal: 27.4s\tremaining: 4m 6s\n",
      "1100:\tlearn: 26.4289151\ttotal: 30.4s\tremaining: 4m 5s\n",
      "1200:\tlearn: 25.7500371\ttotal: 33.4s\tremaining: 4m 4s\n",
      "1300:\tlearn: 25.0498635\ttotal: 36.2s\tremaining: 4m 2s\n",
      "1400:\tlearn: 24.4402644\ttotal: 39.2s\tremaining: 4m\n",
      "1500:\tlearn: 23.9600868\ttotal: 42.4s\tremaining: 4m\n",
      "1600:\tlearn: 23.4730841\ttotal: 45.7s\tremaining: 3m 59s\n",
      "1700:\tlearn: 23.0239954\ttotal: 49.3s\tremaining: 4m\n",
      "1800:\tlearn: 22.5589787\ttotal: 52.9s\tremaining: 4m\n",
      "1900:\tlearn: 22.0027453\ttotal: 56.3s\tremaining: 3m 59s\n",
      "2000:\tlearn: 21.5280748\ttotal: 59.5s\tremaining: 3m 57s\n",
      "2100:\tlearn: 21.0758575\ttotal: 1m 2s\tremaining: 3m 56s\n",
      "2200:\tlearn: 20.6035806\ttotal: 1m 6s\tremaining: 3m 54s\n",
      "2300:\tlearn: 20.0923941\ttotal: 1m 9s\tremaining: 3m 53s\n",
      "2400:\tlearn: 19.6304760\ttotal: 1m 13s\tremaining: 3m 51s\n",
      "2500:\tlearn: 19.1690470\ttotal: 1m 16s\tremaining: 3m 49s\n",
      "2600:\tlearn: 18.7054061\ttotal: 1m 19s\tremaining: 3m 47s\n",
      "2700:\tlearn: 18.3020235\ttotal: 1m 23s\tremaining: 3m 45s\n",
      "2800:\tlearn: 17.8971683\ttotal: 1m 26s\tremaining: 3m 42s\n",
      "2900:\tlearn: 17.5014374\ttotal: 1m 29s\tremaining: 3m 39s\n",
      "3000:\tlearn: 17.1584459\ttotal: 1m 33s\tremaining: 3m 36s\n",
      "3100:\tlearn: 16.7710376\ttotal: 1m 36s\tremaining: 3m 33s\n",
      "3200:\tlearn: 16.4389023\ttotal: 1m 39s\tremaining: 3m 31s\n",
      "3300:\tlearn: 16.1492914\ttotal: 1m 42s\tremaining: 3m 28s\n",
      "3400:\tlearn: 15.8150273\ttotal: 1m 46s\tremaining: 3m 27s\n",
      "3500:\tlearn: 15.5370708\ttotal: 1m 50s\tremaining: 3m 24s\n",
      "3600:\tlearn: 15.2190514\ttotal: 1m 53s\tremaining: 3m 21s\n",
      "3700:\tlearn: 14.9355552\ttotal: 1m 57s\tremaining: 3m 19s\n",
      "3800:\tlearn: 14.6754735\ttotal: 2m\tremaining: 3m 17s\n",
      "3900:\tlearn: 14.3971936\ttotal: 2m 4s\tremaining: 3m 14s\n",
      "4000:\tlearn: 14.1569598\ttotal: 2m 7s\tremaining: 3m 11s\n",
      "4100:\tlearn: 13.8984256\ttotal: 2m 11s\tremaining: 3m 8s\n",
      "4200:\tlearn: 13.6295098\ttotal: 2m 14s\tremaining: 3m 6s\n",
      "4300:\tlearn: 13.4023328\ttotal: 2m 18s\tremaining: 3m 2s\n",
      "4400:\tlearn: 13.1919329\ttotal: 2m 21s\tremaining: 2m 59s\n",
      "4500:\tlearn: 12.9748400\ttotal: 2m 24s\tremaining: 2m 56s\n",
      "4600:\tlearn: 12.7630913\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "4700:\tlearn: 12.5497149\ttotal: 2m 30s\tremaining: 2m 50s\n",
      "4800:\tlearn: 12.3366443\ttotal: 2m 34s\tremaining: 2m 46s\n",
      "4900:\tlearn: 12.1615950\ttotal: 2m 37s\tremaining: 2m 43s\n",
      "5000:\tlearn: 11.9702002\ttotal: 2m 40s\tremaining: 2m 40s\n",
      "5100:\tlearn: 11.7668404\ttotal: 2m 43s\tremaining: 2m 37s\n",
      "5200:\tlearn: 11.5881455\ttotal: 2m 46s\tremaining: 2m 34s\n",
      "5300:\tlearn: 11.4196292\ttotal: 2m 50s\tremaining: 2m 30s\n",
      "5400:\tlearn: 11.2406082\ttotal: 2m 53s\tremaining: 2m 27s\n",
      "5500:\tlearn: 11.0899215\ttotal: 2m 56s\tremaining: 2m 24s\n",
      "5600:\tlearn: 10.9458999\ttotal: 2m 59s\tremaining: 2m 21s\n",
      "5700:\tlearn: 10.7971515\ttotal: 3m 3s\tremaining: 2m 18s\n",
      "5800:\tlearn: 10.6651145\ttotal: 3m 6s\tremaining: 2m 14s\n",
      "5900:\tlearn: 10.5198428\ttotal: 3m 9s\tremaining: 2m 11s\n",
      "6000:\tlearn: 10.3687621\ttotal: 3m 13s\tremaining: 2m 8s\n",
      "6100:\tlearn: 10.2291979\ttotal: 3m 16s\tremaining: 2m 5s\n",
      "6200:\tlearn: 10.0977860\ttotal: 3m 20s\tremaining: 2m 2s\n",
      "6300:\tlearn: 9.9688500\ttotal: 3m 23s\tremaining: 1m 59s\n",
      "6400:\tlearn: 9.8329615\ttotal: 3m 26s\tremaining: 1m 56s\n",
      "6500:\tlearn: 9.7010226\ttotal: 3m 29s\tremaining: 1m 52s\n",
      "6600:\tlearn: 9.5681164\ttotal: 3m 32s\tremaining: 1m 49s\n",
      "6700:\tlearn: 9.4474501\ttotal: 3m 36s\tremaining: 1m 46s\n",
      "6800:\tlearn: 9.3373909\ttotal: 3m 39s\tremaining: 1m 43s\n",
      "6900:\tlearn: 9.2316788\ttotal: 3m 43s\tremaining: 1m 40s\n",
      "7000:\tlearn: 9.0950100\ttotal: 3m 46s\tremaining: 1m 37s\n",
      "7100:\tlearn: 8.9641019\ttotal: 3m 49s\tremaining: 1m 33s\n",
      "7200:\tlearn: 8.8330828\ttotal: 3m 53s\tremaining: 1m 30s\n",
      "7300:\tlearn: 8.7056355\ttotal: 3m 56s\tremaining: 1m 27s\n",
      "7400:\tlearn: 8.5944923\ttotal: 4m\tremaining: 1m 24s\n",
      "7500:\tlearn: 8.4769652\ttotal: 4m 3s\tremaining: 1m 21s\n",
      "7600:\tlearn: 8.3787511\ttotal: 4m 6s\tremaining: 1m 17s\n",
      "7700:\tlearn: 8.2768821\ttotal: 4m 10s\tremaining: 1m 14s\n",
      "7800:\tlearn: 8.1577658\ttotal: 4m 13s\tremaining: 1m 11s\n",
      "7900:\tlearn: 8.0566503\ttotal: 4m 17s\tremaining: 1m 8s\n",
      "8000:\tlearn: 7.9530611\ttotal: 4m 20s\tremaining: 1m 5s\n",
      "8100:\tlearn: 7.8488680\ttotal: 4m 24s\tremaining: 1m 1s\n",
      "8200:\tlearn: 7.7414139\ttotal: 4m 27s\tremaining: 58.7s\n",
      "8300:\tlearn: 7.6400841\ttotal: 4m 30s\tremaining: 55.5s\n",
      "8400:\tlearn: 7.5409817\ttotal: 4m 34s\tremaining: 52.3s\n",
      "8500:\tlearn: 7.4448480\ttotal: 4m 37s\tremaining: 49s\n",
      "8600:\tlearn: 7.3443907\ttotal: 4m 41s\tremaining: 45.7s\n",
      "8700:\tlearn: 7.2458450\ttotal: 4m 44s\tremaining: 42.5s\n",
      "8800:\tlearn: 7.1647105\ttotal: 4m 47s\tremaining: 39.2s\n",
      "8900:\tlearn: 7.0770649\ttotal: 4m 51s\tremaining: 36s\n",
      "9000:\tlearn: 6.9864746\ttotal: 4m 54s\tremaining: 32.7s\n",
      "9100:\tlearn: 6.8939751\ttotal: 4m 58s\tremaining: 29.4s\n",
      "9200:\tlearn: 6.8155701\ttotal: 5m 1s\tremaining: 26.2s\n",
      "9300:\tlearn: 6.7304956\ttotal: 5m 4s\tremaining: 22.9s\n",
      "9400:\tlearn: 6.6450581\ttotal: 5m 8s\tremaining: 19.7s\n",
      "9500:\tlearn: 6.5535993\ttotal: 5m 12s\tremaining: 16.4s\n",
      "9600:\tlearn: 6.4757394\ttotal: 5m 16s\tremaining: 13.2s\n",
      "9700:\tlearn: 6.4064269\ttotal: 5m 20s\tremaining: 9.87s\n",
      "9800:\tlearn: 6.3182378\ttotal: 5m 23s\tremaining: 6.57s\n",
      "9900:\tlearn: 6.2349518\ttotal: 5m 27s\tremaining: 3.27s\n",
      "9999:\tlearn: 6.1630591\ttotal: 5m 30s\tremaining: 0us\n",
      "Final blended predictions for the test dataset:\n",
      "[177 207 206 ... 203 183 156]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average weights from cross-validation\n",
    "average_weights = np.mean(optimized_weights_list, axis=0)\n",
    "\n",
    "# Train models on the entire training dataset\n",
    "final_model1 = lgb.LGBMRegressor(\n",
    "    learning_rate=0.01, n_estimators=1000, random_state=42,\n",
    "     metric='RMSE' # feature_fraction=0.8, bagging_fraction=0.8,\n",
    ")\n",
    "final_model1.fit(merged_df, y)\n",
    "\n",
    "final_model2 = CatBoostRegressor(\n",
    "    iterations=10000, learning_rate=0.01, depth=10, loss_function='RMSE',\n",
    "    cat_features=merged_df.select_dtypes(include=['object', 'category']).columns.to_list(),\n",
    "    verbose=100\n",
    ")\n",
    "final_model2.fit(merged_df, y)\n",
    "\n",
    "final_model3 = XGBRegressor(n_estimators=10000, learning_rate=0.01,\n",
    "        max_depth=3, random_state=42, \n",
    "        enable_categorical=True,\n",
    "        eval_metric=root_mean_squared_error)\n",
    "final_model3.fit(merged_df, y)\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "test_pred1 = final_model1.predict(merged_test)\n",
    "test_pred2 = final_model2.predict(merged_test)\n",
    "test_pred3 = final_model3.predict(merged_test)\n",
    "\n",
    "# Combine the predictions using the average weights\n",
    "final_test_predictions = (\n",
    "    average_weights[0] * test_pred1 + average_weights[1] * test_pred2 + average_weights[2] * test_pred3\n",
    ")\n",
    "\n",
    "# Optionally round predictions if required (e.g., for classification tasks)\n",
    "final_test_predictions = np.round(final_test_predictions).astype(int)\n",
    "\n",
    "# Display final predictions\n",
    "print(\"Final blended predictions for the test dataset:\")\n",
    "print(final_test_predictions)\n",
    "\n",
    "ss['composite_score']=final_test_predictions\n",
    "#generate submission\n",
    "ss.to_csv('../dataset/LGBM_and_CatBoost_and_XGBoost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
